{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b05e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import  NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deced97",
   "metadata": {},
   "source": [
    "<b> Question 1 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a06050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naukri_bangalore(url):\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "    search_field_designation.send_keys(\"Data Analyst\")\n",
    "\n",
    "    search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "    search_field_location.send_keys(\"Bangalore\")\n",
    "    \n",
    "    search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "    search_button.click()\n",
    "    \n",
    "    job_title=[]\n",
    "    titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for i in titles:\n",
    "        job_title.append(i.text)\n",
    "        \n",
    "    job_location=[]\n",
    "    location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "    for i in location:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "    company_name=[]\n",
    "    companies=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    for i in companies:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "    Experience=[]\n",
    "    experience_tag=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')\n",
    "    for i in experience_tag:\n",
    "        Experience.append(i.text)\n",
    "        \n",
    "    driver.close()\n",
    "        \n",
    "    print(len(job_title), len(job_location))\n",
    "    print(len(company_name), len(Experience))\n",
    "    \n",
    "    data_analyst_jobs=pd.DataFrame({})\n",
    "    data_analyst_jobs['Job Title']=job_title[0:10]    \n",
    "    data_analyst_jobs['Job Location']=job_location[0:10]\n",
    "    data_analyst_jobs['Company Name']=company_name[0:10]\n",
    "    data_analyst_jobs['Experience Required']=Experience[0:10]\n",
    "    print(\"Shape of dataset is {} rows and {} columns\".format(*data_analyst_jobs.shape))\n",
    "    return data_analyst_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ee7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "naukri_bangalore(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669d951",
   "metadata": {},
   "source": [
    "<b> Question 10 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede30c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laptop(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    item_title=[]\n",
    "    price=[]\n",
    "    rating=[]\n",
    "    \n",
    "    #Let's search for laptop product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "    driver.find_element_by_xpath('//input[@type=\"submit\"]').click()\n",
    "        \n",
    "    #Let's apply filter for \"Intel Core i7\"\n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a',).click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's apply filter for \"Intel Core i9\"  \n",
    "    driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a').click()\n",
    "        \n",
    "    # Let's scrape the data\n",
    "    titles=driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "    for i in titles:\n",
    "        item_title.append(i.text)\n",
    "    prices=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    ratings=driver.find_elements_by_xpath('//div[@class=\"a-row a-size-small\"]/span[1]')   \n",
    "    for i in ratings:\n",
    "        rating.append(i.get_attribute('aria-label'))\n",
    "        \n",
    "    # Let's create a DataFrame for our data\n",
    "    amazon_laptops=pd.DataFrame({})\n",
    "    amazon_laptops['Title']=item_title[:10]\n",
    "    amazon_laptops['Price']=price[:10]\n",
    "    amazon_laptops['Rating']=rating[:10]\n",
    "    return amazon_laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ac215",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23bdac",
   "metadata": {},
   "source": [
    "<b> Question 9 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shoes_myntra(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    brand_name=[]\n",
    "    description=[]\n",
    "    product_price=[]\n",
    "    \n",
    "    #Let's apply filter for price\n",
    "    driver.find_element_by_xpath('//ul[@class=\"price-list\"]/li[2]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's apply filter for colour\n",
    "    driver.find_element_by_xpath('//span[@data-colorhex=\"black\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<2:\n",
    "        time.sleep(5)\n",
    "        \n",
    "        brands=driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "        for q in brands:\n",
    "            brand_name.append(q.text)\n",
    "        \n",
    "        descs=driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "        for q in descs:\n",
    "            description.append(q.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "        for q in prices:\n",
    "            product_price.append(q.text)\n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@rel=\"next\"]').click()    \n",
    "        time.sleep(5)\n",
    "        j+=1\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    myntra_shoes=pd.DataFrame({})\n",
    "    myntra_shoes['Brand of the Shoes']=brand_name[0:100]\n",
    "    myntra_shoes['Short Shoes Description']=description[0:100]\n",
    "    myntra_shoes['Price of the Shoes']=product_price[0:100]\n",
    "    return myntra_shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoes_myntra('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336bd1e4",
   "metadata": {},
   "source": [
    "<b> Question 8 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e29e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_sneakers(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    #Let's navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's search for sneaker product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sneakers')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    sneaker_brand_name=[]\n",
    "    sneaker_description=[]\n",
    "    sneaker_price=[]\n",
    "    sneaker_discount=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sneaker_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sneaker_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sneaker_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sneaker_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    # Let's create a DataFrame for our data   \n",
    "    sneakers_flipkart=pd.DataFrame({})\n",
    "    sneakers_flipkart['Brand Name']=sneaker_brand_name[:100]\n",
    "    sneakers_flipkart['Product Descriptions']=sneaker_description[:100]\n",
    "    sneakers_flipkart['Price']=sneaker_price[:100]\n",
    "    sneakers_flipkart['Discount %']=sneaker_discount[:100]\n",
    "    return sneakers_flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7222ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_sneakers('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c7887",
   "metadata": {},
   "source": [
    "<b> Question 7 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iphone_100_review(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    rating=[]\n",
    "    review_summary=[]\n",
    "    full_review=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<10:\n",
    "    \n",
    "        ratings=driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        for i in ratings:\n",
    "            rating.append(i.text)\n",
    "        \n",
    "        reviews=driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "        for i in reviews:\n",
    "            review_summary.append(i.text)\n",
    "        \n",
    "        full_reviews=driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "        for i in full_reviews:\n",
    "            full_review.append(i.text)\n",
    "        time.sleep(10)    \n",
    "        \n",
    "        driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        time.sleep(10)\n",
    "        j+=1\n",
    "        time.sleep(10)\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    iphone_review=pd.DataFrame({})\n",
    "    iphone_review['Rating']=rating\n",
    "    iphone_review['Review Summary']=review_summary\n",
    "    iphone_review['Full Reviews']=full_review\n",
    "    return iphone_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a44f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_100_review('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a4d7b",
   "metadata": {},
   "source": [
    "<b> Question 6 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_sunglasses(url):\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(10)\n",
    "    \n",
    "    #Let's navigate to search bar\n",
    "    driver.find_element_by_xpath('//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's search for sunglasses product and then click search button\n",
    "    driver.find_element_by_xpath('//input[@title=\"Search for products, brands and more\"]').send_keys('sunglasses')\n",
    "    driver.find_element_by_xpath('//button[@type=\"submit\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    sunglass_brand_name=[]\n",
    "    sunglass_description=[]\n",
    "    sunglass_price=[]\n",
    "    sunglass_discount=[]\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    j=0\n",
    "    while j<3:\n",
    "        time.sleep(3)\n",
    "        brands=driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "        for brand in brands:\n",
    "            sunglass_brand_name.append(brand.text)\n",
    "        \n",
    "        descriptions=driver.find_elements_by_xpath('//a[contains(@class,\"IRpwTa\")]')\n",
    "        for description in descriptions:\n",
    "            sunglass_description.append(description.text)\n",
    "        \n",
    "        prices=driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "        for price in prices:\n",
    "            sunglass_price.append(price.text)\n",
    "        \n",
    "        discounts=driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "        for discount in discounts:\n",
    "            sunglass_discount.append(discount.text)\n",
    "        if j==0:\n",
    "            driver.find_element_by_xpath('//a[@class=\"_1LKTO3\"]').click()\n",
    "        elif j==1:\n",
    "            driver.find_element_by_xpath('//nav[@class=\"yFHi8N\"]/a[12]').click()\n",
    "        else:\n",
    "            pass\n",
    "        j+=1\n",
    "        \n",
    "    # Let's create a DataFrame for our data   \n",
    "    sunglasses_flip=pd.DataFrame({})\n",
    "    sunglasses_flip['Product Brand']=sunglass_brand_name[:100]\n",
    "    sunglasses_flip['Product Description']=sunglass_description[:100]\n",
    "    sunglasses_flip['Price of Product']=sunglass_price[:100]\n",
    "    sunglasses_flip['Discount on Product']=sunglass_discount[:100]\n",
    "    return sunglasses_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flipkart_sunglasses('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f9c2b",
   "metadata": {},
   "source": [
    "<b> Question 5 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b1ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gd_salary_full(url):\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    gd_min_salary=[]\n",
    "    gd_max_salary=[]\n",
    "    gd_avg_salary=[]\n",
    "    gd_company_name=[]\n",
    "    gd_rating=[]\n",
    "    #temp=[]\n",
    "\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    #Let's navigate to search bar and then type the Data Scientist job, location Noida and then click search button\n",
    "    driver.find_element_by_xpath('//*[@id=\"KeywordSearch\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys(Keys.CONTROL+'a')\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys(Keys.DELETE)\n",
    "    driver.find_element_by_xpath('//*[@id=\"LocationSearch\"]').send_keys('Noida (India)')\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-btn-mkt\"]').click()\n",
    "    time.sleep(8)\n",
    "    \n",
    "    #Let's search the element for required details\n",
    "    companies=driver.find_elements_by_xpath('//div[@data-test=\"job-info\"]/p[2]')\n",
    "    avg_salary=driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]/strong')\n",
    "    min_salary=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]/span[1]')\n",
    "    max_salary=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values d-flex justify-content-between \"]/span[2]')\n",
    "#     rating='NA'\n",
    "    \n",
    "    # Let's scrape the data\n",
    "    for i in companies:\n",
    "        gd_company_name.append(i.text)\n",
    "    for i in avg_salary:\n",
    "        gd_avg_salary.append(i.text)\n",
    "    for i in min_salary:\n",
    "        gd_min_salary.append(i.text)\n",
    "    for i in max_salary:\n",
    "        gd_max_salary.append(i.text)\n",
    "        \n",
    "    # Let's create a DataFrame for our data\n",
    "    salaries=pd.DataFrame({})\n",
    "    salaries['Company Name']=gd_company_name[:10]\n",
    "    salaries['Avgerage Salary']=gd_avg_salary[:10]\n",
    "    salaries['Minimum Salary']=gd_min_salary[:10]\n",
    "    salaries['Maximum Salary']=gd_max_salary[:10]\n",
    "    \n",
    "    driver.get('https://www.glassdoor.co.in/profile/login_input.htm?userOriginHook=HEADER_SIGNIN_LINK')\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//input[@id=\"userEmail\"]').send_keys('glassdoortestassignment@gmail.com')\n",
    "    driver.find_element_by_xpath('//input[@id=\"userPassword\"]').send_keys('Assignment@1234')\n",
    "    time.sleep(5)\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()\n",
    "    time.sleep(10)\n",
    "    for i in gd_company_name[:11]:\n",
    "        driver.find_element_by_xpath('//*[@id=\"sc.keyword\"]').send_keys(i)\n",
    "        driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.CONTROL+'a')\n",
    "        driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.DELETE)\n",
    "        time.sleep(3)\n",
    "        driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button').click()\n",
    "        time.sleep(8)\n",
    "        try:\n",
    "            gd_rating.append((driver.find_element_by_xpath('//span[@data-test=\"detailRating\"]')).text.replace('\\n', ''))\n",
    "        except:\n",
    "            gd_rating.append('NA')\n",
    "        time.sleep(7)   \n",
    "        driver.back()\n",
    "        time.sleep(5) \n",
    "    \n",
    "    salaries['Rating']=gd_rating[:10]\n",
    "    \n",
    "    return salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b7c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_salary_full('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62570fa9",
   "metadata": {},
   "source": [
    "<b> Question 4 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glass_door_job(url):\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    job_title=[]\n",
    "    company_name=[]\n",
    "    rating=[]\n",
    "    days=[]\n",
    "    temp = []\n",
    "    \n",
    "    # Let's load the drivers and URL\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # If we visit the glassdoor page we will observe that, to navigate into the page we have to do the login\n",
    "    # Let's click on the sign-in butoon for logining\n",
    "    #driver.find_element_by_xpath('//*[@id=\"SiteNav\"]/nav/div[1]/div[1]/button').click()\n",
    "\n",
    "        \n",
    "    #Let's enter the demo login details\n",
    "    driver.find_element_by_xpath('//input[@id=\"userEmail\"]').send_keys('glassdoortestassignment@gmail.com')\n",
    "    driver.find_element_by_xpath('//input[@id=\"userPassword\"]').send_keys('Assignment@1234')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's maximize the window size because there are some text font size is will has other element details in short window\n",
    "    driver.find_element_by_xpath('//button[@class=\"gd-ui-button minWidthBtn css-8i7bc2\"]').click()\n",
    "    driver.maximize_window()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #Let's fill the requied details in search column and click search\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.keyword\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.CONTROL+'a')\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys(Keys.DELETE)\n",
    "    driver.find_element_by_xpath('//*[@id=\"sc.location\"]').send_keys('Noida (India)')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #Let's search the desired detail which we hve entered\n",
    "    driver.find_element_by_xpath('//*[@id=\"scBar\"]/div/button').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    jobs=driver.find_elements_by_xpath('//article[@id=\"MainCol\"]/div/ul/li')\n",
    "    for job in jobs:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('//*[@id=\"JAModal\"]/div/div[2]/span').click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        job.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "        # Let's scrape the data\n",
    "        job_title.append((driver.find_element_by_xpath('//div[@class=\"css-1vg6q84 e1tk4kwz4\"]')).text)\n",
    "        temp.append((driver.find_element_by_xpath('//div[@class=\"css-87uc0g e1tk4kwz1\"]')).text.replace('\\n',''))\n",
    "        for i in temp:\n",
    "            for j in i:\n",
    "                res = ''.join(j for j in i if not j.isdigit())\n",
    "                fin = res.replace('.', '')\n",
    "            company_name.append(fin)\n",
    "        try:\n",
    "            rating.append((driver.find_element_by_xpath('//span[@data-test=\"detailRating\"]')).text)\n",
    "        except:\n",
    "            rating.append('NA')\n",
    "        try:\n",
    "            days.append((driver.find_element_by_xpath('//div[@data-test=\"job-age\"]')).text)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    job_glass_door=pd.DataFrame({})\n",
    "    job_glass_door['Job Title']=job_title[0:10]\n",
    "    job_glass_door['Company Name']=company_name[0:10]\n",
    "    job_glass_door['Ratings']=rating[0:10]\n",
    "    job_glass_door['Job Posted']=days[0:10]\n",
    "    return job_glass_door"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eaa4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "glass_door_job('https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54bb54b",
   "metadata": {},
   "source": [
    "<b> Question 3 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobs_data_Scientist(url):\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create empty list for storing the data\n",
    "    ds_job_title=[]\n",
    "    ds_company_name=[]\n",
    "    ds_location=[]\n",
    "    ds_experience=[]\n",
    "    ds_salary=[]\n",
    "    \n",
    "    #Let's navigate to the search column\n",
    "    driver.find_element_by_xpath('//input[@class=\"sugInp\"]').send_keys('Data Scientist')\n",
    "    driver.find_element_by_xpath('//button[@class=\"btn\"]').click()\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Let's create filter for job location\n",
    "    driver.find_element_by_xpath('//span[@title=\"Delhi / NCR\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's create filter for salary\n",
    "    driver.find_element_by_xpath('//span[@title=\"3-6 Lakhs\"]').click()\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Let's scrape the job tile\n",
    "    job_titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for i in job_titles:\n",
    "        ds_job_title.append(i.text)\n",
    "    \n",
    "    # Let's scrape the company name\n",
    "    company_name=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "    for i in company_name:\n",
    "        ds_company_name.append(i.text)\n",
    "    \n",
    "    # Let's scrape the company location    \n",
    "    location=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "    for i in location:\n",
    "        ds_location.append(i.text)\n",
    "    \n",
    "        \n",
    "    # Let's scrape the experience\n",
    "    experience=driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')\n",
    "    for i in experience:\n",
    "        ds_experience.append(i.text)\n",
    "    \n",
    "    # Let's scrape the salary\n",
    "    salary=driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "    for i in salary:\n",
    "        ds_salary.append(i.text)\n",
    "    \n",
    "    # Let's create a DataFrame for our data\n",
    "    ds_jobs=pd.DataFrame({})\n",
    "    ds_jobs['Job Title']=ds_job_title[0:10]\n",
    "    ds_jobs['Company Name']=ds_company_name[0:10]\n",
    "    ds_jobs['Job Location']=ds_location[0:10]\n",
    "    ds_jobs['Experience']=ds_experience[0:10]\n",
    "    return ds_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_data_Scientist('https://www.naukri.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db68f7",
   "metadata": {},
   "source": [
    "<b> Question 2 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b8611",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=(\"https://www.naukri.com/\")\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "\n",
    "#Let's enter the job title and location\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "job_description=[]\n",
    "\n",
    "titles=driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in titles:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "location=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in location:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "companies=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in companies:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "for url in urls[0:10]:\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        job_description.append(description)\n",
    "    except NoSuchElementException :\n",
    "        job_description.append(\"Not Available\")\n",
    "        \n",
    "data_scientist_jobs=pd.DataFrame({})\n",
    "data_scientist_jobs['Job Title']=job_title[0:10]    \n",
    "data_scientist_jobs['Job Location']=job_location[0:10]\n",
    "data_scientist_jobs['Company Name']=company_name[0:10]\n",
    "data_scientist_jobs['Detailed Job Description']=job_description[0:10]\n",
    "data_scientist_jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
