{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214de89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda2\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\programdata\\anaconda2\\lib\\site-packages (from selenium) (1.26.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cikit-learn (c:\\programdata\\anaconda2\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d89bb6",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24ac4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae54483",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6aa59b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1=[]\n",
    "author1=[]\n",
    "vertical1=[]\n",
    "headline1=[]\n",
    "description1=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a97d42e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame({})\n",
    "df1['Date']=date1[:1]\n",
    "df1['Author']=author1[:1]\n",
    "df1['Vertical']=vertical1[:1]\n",
    "df1['Healines']=headline1[:1]\n",
    "df1['Description']=description1[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c3c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2dcb2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1a=[]\n",
    "author1a=[]\n",
    "vertical1a=[]\n",
    "headline1a=[]\n",
    "description1a=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1a.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1a.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1a.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "66cbf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1a=pd.DataFrame({})\n",
    "df1a['Date']=date1a[:1]\n",
    "df1a['Author']=author1a[:1]\n",
    "df1a['Vertical']=vertical1a[:1]\n",
    "df1a['Healines']=headline1a[:1]\n",
    "df1a['Description']=description1a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2cd32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf885f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "925cd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1b=[]\n",
    "author1b=[]\n",
    "vertical1b=[]\n",
    "headline1b=[]\n",
    "description1b=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1b.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1b.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Cricket']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1b.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f21ab98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1b=pd.DataFrame({})\n",
    "df1b['Date']=date1b[:1]\n",
    "df1b['Author']=author1b[:1]\n",
    "df1b['Vertical']=vertical1b[:1]\n",
    "df1b['Healines']=headline1b[:1]\n",
    "df1b['Description']=description1b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083c5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2ff1a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1c=[]\n",
    "author1c=[]\n",
    "vertical1c=[]\n",
    "headline1c=[]\n",
    "description1c=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1c.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1c.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|City']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1c.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2282ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1c=pd.DataFrame({})\n",
    "df1c['Date']=date1c[:1]\n",
    "df1c['Author']=author1c[:1]\n",
    "df1c['Vertical']=vertical1c[:1]\n",
    "df1c['Healines']=headline1c[:1]\n",
    "df1c['Description']=description1c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688323ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "32384b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1d=[]\n",
    "author1d=[]\n",
    "vertical1d=[]\n",
    "headline1d=[]\n",
    "description1d=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1d.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1d.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|madurai']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1d.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fbc2d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1d=pd.DataFrame({})\n",
    "df1d['Date']=date1d[:1]\n",
    "df1d['Author']=author1d[:1]\n",
    "df1d['Vertical']=vertical1d[:1]\n",
    "df1d['Healines']=headline1d[:1]\n",
    "df1d['Description']=description1d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6a4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f74057b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1e=[]\n",
    "author1e=[]\n",
    "vertical1e=[]\n",
    "headline1e=[]\n",
    "description1e=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1e.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1e.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1e.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2d5124d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1e=pd.DataFrame({})\n",
    "df1e['Date']=date1e[:1]\n",
    "df1e['Author']=author1e[:1]\n",
    "df1e['Vertical']=vertical1e[:1]\n",
    "df1e['Healines']=headline1e[:1]\n",
    "df1e['Description']=description1e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3352f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "57ca5929",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1f=[]\n",
    "author1f=[]\n",
    "vertical1f=[]\n",
    "headline1f=[]\n",
    "description1f=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1f.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1f.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|sports']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1f.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cc596a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1f=pd.DataFrame({})\n",
    "df1f['Date']=date1f[:1]\n",
    "df1f['Author']=author1f[:1]\n",
    "df1f['Vertical']=vertical1f[:1]\n",
    "df1f['Healines']=headline1f[:1]\n",
    "df1f['Description']=description1f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9978e1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ddfbf203",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1g=[]\n",
    "author1g=[]\n",
    "vertical1g=[]\n",
    "headline1g=[]\n",
    "description1g=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1g.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1g.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|trichy']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1g.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ed48cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1g=pd.DataFrame({})\n",
    "df1g['Date']=date1g[:1]\n",
    "df1g['Author']=author1g[:1]\n",
    "df1g['Vertical']=vertical1g[:1]\n",
    "df1g['Healines']=headline1g[:1]\n",
    "df1g['Description']=description1g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56be623a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "683a8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1h=[]\n",
    "author1h=[]\n",
    "vertical1h=[]\n",
    "headline1h=[]\n",
    "description1h=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1h.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1h.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ahmedabad']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1h.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ed2880e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1h=pd.DataFrame({})\n",
    "df1h['Date']=date1h[:1]\n",
    "df1h['Author']=author1h[:1]\n",
    "df1h['Vertical']=vertical1h[:1]\n",
    "df1h['Healines']=headline1h[:1]\n",
    "df1h['Description']=description1h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefbb48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d1a0709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1i=[]\n",
    "author1i=[]\n",
    "vertical1i=[]\n",
    "headline1i=[]\n",
    "description1i=[]\n",
    "\n",
    "# scrapping details 1 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date1i.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author1i.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical1i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline1i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description1i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description1i.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "64ba0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1i=pd.DataFrame({})\n",
    "df1i['Date']=date1i[:1]\n",
    "df1i['Author']=author1i[:1]\n",
    "df1i['Vertical']=vertical1i[:1]\n",
    "df1i['Healines']=headline1i[:1]\n",
    "df1i['Description']=description1i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf99731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e10ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3737de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2=[]\n",
    "author2=[]\n",
    "vertical2=[]\n",
    "headline2=[]\n",
    "description2=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|City']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a4950d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({})\n",
    "df2['Date']=date2[:1]\n",
    "df2['Author']=author2[:1]\n",
    "df2['Vertical']=vertical2[:1]\n",
    "df2['Healines']=headline2[:1]\n",
    "df2['Description']=description2[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a9c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8749453",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2a=[]\n",
    "author2a=[]\n",
    "vertical2a=[]\n",
    "headline2a=[]\n",
    "description2a=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2a.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2a.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2a.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1c494a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2a=pd.DataFrame({})\n",
    "df2a['Date']=date2a[:1]\n",
    "df2a['Author']=author2a[:1]\n",
    "df2a['Vertical']=vertical2a[:1]\n",
    "df2a['Healines']=headline2a[:1]\n",
    "df2a['Description']=description2a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb8e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5977b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2b=[]\n",
    "author2b=[]\n",
    "vertical2b=[]\n",
    "headline2b=[]\n",
    "description2b=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2b.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2b.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2b.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b792f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2b=pd.DataFrame({})\n",
    "df2b['Date']=date2b[:1]\n",
    "df2b['Author']=author2b[:1]\n",
    "df2b['Vertical']=vertical2b[:1]\n",
    "df2b['Healines']=headline2b[:1]\n",
    "df2b['Description']=description2b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cecc98d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaf92242",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2c=[]\n",
    "author2c=[]\n",
    "vertical2c=[]\n",
    "headline2c=[]\n",
    "description2c=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2c.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2c.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2c.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f25a7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2c=pd.DataFrame({})\n",
    "df2c['Date']=date2c[:1]\n",
    "df2c['Author']=author2c[:1]\n",
    "df2c['Vertical']=vertical2c[:1]\n",
    "df2c['Healines']=headline2c[:1]\n",
    "df2c['Description']=description2c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf54182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2de2b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2d=[]\n",
    "author2d=[]\n",
    "vertical2d=[]\n",
    "headline2d=[]\n",
    "description2d=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2d.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2d.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2d.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e2f4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2d=pd.DataFrame({})\n",
    "df2d['Date']=date2d[:1]\n",
    "df2d['Author']=author2d[:1]\n",
    "df2d['Vertical']=vertical2d[:1]\n",
    "df2d['Healines']=headline2d[:1]\n",
    "df2d['Description']=description2d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6f87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0b0bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2e=[]\n",
    "author2e=[]\n",
    "vertical2e=[]\n",
    "headline2e=[]\n",
    "description2e=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2e.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2e.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|City']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2e.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d805317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2e=pd.DataFrame({})\n",
    "df2e['Date']=date2e[:1]\n",
    "df2e['Author']=author2e[:1]\n",
    "df2e['Vertical']=vertical2e[:1]\n",
    "df2e['Healines']=headline2e[:1]\n",
    "df2e['Description']=description2e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d570c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eec31a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2f=[]\n",
    "author2f=[]\n",
    "vertical2f=[]\n",
    "headline2f=[]\n",
    "description2f=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2f.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2f.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2f.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da2d4caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2f=pd.DataFrame({})\n",
    "df2f['Date']=date2f[:1]\n",
    "df2f['Author']=author2f[:1]\n",
    "df2f['Vertical']=vertical2f[:1]\n",
    "df2f['Healines']=headline2f[:1]\n",
    "df2f['Description']=description2f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dcb0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ead5be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2g=[]\n",
    "author2g=[]\n",
    "vertical2g=[]\n",
    "headline2g=[]\n",
    "description2g=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2g.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2g.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|world']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2g.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba7aaca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2g=pd.DataFrame({})\n",
    "df2g['Date']=date2g[:1]\n",
    "df2g['Author']=author2g[:1]\n",
    "df2g['Vertical']=vertical2g[:1]\n",
    "df2g['Healines']=headline2g[:1]\n",
    "df2g['Description']=description2g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0245707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d119bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2h=[]\n",
    "author2h=[]\n",
    "vertical2h=[]\n",
    "headline2h=[]\n",
    "description2h=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2h.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2h.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Business']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2h.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c989a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2h=pd.DataFrame({})\n",
    "df2h['Date']=date2h[:1]\n",
    "df2h['Author']=author2h[:1]\n",
    "df2h['Vertical']=vertical2h[:1]\n",
    "df2h['Healines']=headline2h[:1]\n",
    "df2h['Description']=description2h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37a5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "31c0f0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date2i=[]\n",
    "author2i=[]\n",
    "vertical2i=[]\n",
    "headline2i=[]\n",
    "description2i=[]\n",
    "\n",
    "# scrapping details 2 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date2i.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author2i.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical2i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline2i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description2i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description2i.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77974b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2i=pd.DataFrame({})\n",
    "df2i['Date']=date2i[:1]\n",
    "df2i['Author']=author2i[:1]\n",
    "df2i['Vertical']=vertical2i[:1]\n",
    "df2i['Healines']=headline2i[:1]\n",
    "df2i['Description']=description2i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2617dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447a233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "241b42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3=[]\n",
    "author3=[]\n",
    "vertical3=[]\n",
    "headline3=[]\n",
    "description3=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd0f3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame({})\n",
    "df3['Date']=date3[:1]\n",
    "df3['Author']=author3[:1]\n",
    "df3['Vertical']=vertical3[:1]\n",
    "df3['Healines']=headline3[:1]\n",
    "df3['Description']=description3[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416c76c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac5d0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3a=[]\n",
    "author3a=[]\n",
    "vertical3a=[]\n",
    "headline3a=[]\n",
    "description3a=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3a.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3a.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3a.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3a.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3a.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7eb47c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3a=pd.DataFrame({})\n",
    "df3a['Date']=date3a[:1]\n",
    "df3a['Author']=author3a[:1]\n",
    "df3a['Vertical']=vertical3a[:1]\n",
    "df3a['Healines']=headline3a[:1]\n",
    "df3a['Description']=description3a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e96f33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b205e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3b=[]\n",
    "author3b=[]\n",
    "vertical3b=[]\n",
    "headline3b=[]\n",
    "description3b=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3b.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3b.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3b.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3b.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3b.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a3923f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3b=pd.DataFrame({})\n",
    "df3b['Date']=date3b[:1]\n",
    "df3b['Author']=author3b[:1]\n",
    "df3b['Vertical']=vertical3b[:1]\n",
    "df3b['Healines']=headline3b[:1]\n",
    "df3b['Description']=description3b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece13483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6480ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3c=[]\n",
    "author3c=[]\n",
    "vertical3c=[]\n",
    "headline3c=[]\n",
    "description3c=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3c.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3c.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3c.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3c.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3c.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36f6f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3c=pd.DataFrame({})\n",
    "df3c['Date']=date3c[:1]\n",
    "df3c['Author']=author3c[:1]\n",
    "df3c['Vertical']=vertical3c[:1]\n",
    "df3c['Healines']=headline3c[:1]\n",
    "df3c['Description']=description3c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e8cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88b950d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3d=[]\n",
    "author3d=[]\n",
    "vertical3d=[]\n",
    "headline3d=[]\n",
    "description3d=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3d.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3d.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3d.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3d.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3d.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fe1aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3d=pd.DataFrame({})\n",
    "df3d['Date']=date3d[:1]\n",
    "df3d['Author']=author3d[:1]\n",
    "df3d['Vertical']=vertical3d[:1]\n",
    "df3d['Healines']=headline3d[:1]\n",
    "df3d['Description']=description3d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc429a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6029a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3e=[]\n",
    "author3e=[]\n",
    "vertical3e=[]\n",
    "headline3e=[]\n",
    "description3e=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3e.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3e.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|City']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3e.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3e.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3e.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbcbe8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3e=pd.DataFrame({})\n",
    "df3e['Date']=date3e[:1]\n",
    "df3e['Author']=author3e[:1]\n",
    "df3e['Vertical']=vertical3e[:1]\n",
    "df3e['Healines']=headline3e[:1]\n",
    "df3e['Description']=description3e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b15871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9544922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3f=[]\n",
    "author3f=[]\n",
    "vertical3f=[]\n",
    "headline3f=[]\n",
    "description3f=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3f.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3f.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3f.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3f.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3f.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02a20286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3f=pd.DataFrame({})\n",
    "df3f['Date']=date3f[:1]\n",
    "df3f['Author']=author3f[:1]\n",
    "df3f['Vertical']=vertical3f[:1]\n",
    "df3f['Healines']=headline3f[:1]\n",
    "df3f['Description']=description3f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ef142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1ced1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3g=[]\n",
    "author3g=[]\n",
    "vertical3g=[]\n",
    "headline3g=[]\n",
    "description3g=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3g.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3g.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3g.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3g.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3g.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea21c450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3g=pd.DataFrame({})\n",
    "df3g['Date']=date3g[:1]\n",
    "df3g['Author']=author3g[:1]\n",
    "df3g['Vertical']=vertical3g[:1]\n",
    "df3g['Healines']=headline3g[:1]\n",
    "df3g['Description']=description3g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431058e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56b317c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3h=[]\n",
    "author3h=[]\n",
    "vertical3h=[]\n",
    "headline3h=[]\n",
    "description3h=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3h.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3h.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|City']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3h.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3h.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3h.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a6ba93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3h=pd.DataFrame({})\n",
    "df3h['Date']=date3h[:1]\n",
    "df3h['Author']=author3h[:1]\n",
    "df3h['Vertical']=vertical3h[:1]\n",
    "df3h['Healines']=headline3h[:1]\n",
    "df3h['Description']=description3h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c47dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43e4c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "date3i=[]\n",
    "author3i=[]\n",
    "vertical3i=[]\n",
    "headline3i=[]\n",
    "description3i=[]\n",
    "\n",
    "# scrapping details 3 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    try:\n",
    "        date3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        date3i.append('-')\n",
    "        \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "    try:\n",
    "        author3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        author3i.append('-')\n",
    "    \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Business']\")\n",
    "for i in ve:\n",
    "    try:\n",
    "        vertical3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        vertical3i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "    try:\n",
    "        headline3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        headline3i.append('-')\n",
    "   \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    try:\n",
    "        description3i.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        description3i.append('-')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6c740eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3i=pd.DataFrame({})\n",
    "df3i['Date']=date3i[:1]\n",
    "df3i['Author']=author3i[:1]\n",
    "df3i['Vertical']=vertical3i[:1]\n",
    "df3i['Healines']=headline3i[:1]\n",
    "df3i['Description']=description3i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bdec49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b986b55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dddaa277",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4=[]\n",
    "author4=[]\n",
    "vertical4=[]\n",
    "headline4=[]\n",
    "description4=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author4.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|world']\")\n",
    "for i in ve:\n",
    "    vertical4.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "813640c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.DataFrame({})\n",
    "df4['Date']=date4[:1]\n",
    "df4['Author']=author4[:1]\n",
    "df4['Vertical']=vertical4[:1]\n",
    "df4['Healines']=headline4[:1]\n",
    "df4['Description']=description4[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab0003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94e3fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4a=[]\n",
    "author4a=[]\n",
    "vertical4a=[]\n",
    "headline4a=[]\n",
    "description4a=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4a.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author4a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|City']\")\n",
    "for i in ve:\n",
    "    vertical4a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64502dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4a=pd.DataFrame({})\n",
    "df4a['Date']=date4a[:1]\n",
    "df4a['Author']=author4a[:1]\n",
    "df4a['Vertical']=vertical4a[:1]\n",
    "df4a['Healines']=headline4a[:1]\n",
    "df4a['Description']=description4a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be6a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5f3734e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4b=[]\n",
    "author4b=[]\n",
    "vertical4b=[]\n",
    "headline4b=[]\n",
    "description4b=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4b.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author4b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical4b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dba61681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4b=pd.DataFrame({})\n",
    "df4b['Date']=date4b[:1]\n",
    "df4b['Author']=author4b[:1]\n",
    "df4b['Vertical']=vertical4b[:1]\n",
    "df4b['Healines']=headline4b[:1]\n",
    "df4b['Description']=description4b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58aff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37d87ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4c=[]\n",
    "author4c=[]\n",
    "vertical4c=[]\n",
    "headline4c=[]\n",
    "description4c=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4c.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author4c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|shimla']\")\n",
    "for i in ve:\n",
    "    vertical4c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "afbc203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4c=pd.DataFrame({})\n",
    "df4c['Date']=date4c[:1]\n",
    "df4c['Author']=author4c[:1]\n",
    "df4c['Vertical']=vertical4c[:1]\n",
    "df4c['Healines']=headline4c[:1]\n",
    "df4c['Description']=description4c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a514d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8c6e2b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4d=[]\n",
    "author4d=[]\n",
    "vertical4d=[]\n",
    "headline4d=[]\n",
    "description4d=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4d.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author4d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical4d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21262ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4d=pd.DataFrame({})\n",
    "df4d['Date']=date4d[:1]\n",
    "df4d['Author']=author4d[:1]\n",
    "df4d['Vertical']=vertical4d[:1]\n",
    "df4d['Healines']=headline4d[:1]\n",
    "df4d['Description']=description4d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4693c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d6c18cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4e=[]\n",
    "author4e=[]\n",
    "vertical4e=[]\n",
    "headline4e=[]\n",
    "description4e=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4e.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author4e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    vertical4e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d0f7cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4e=pd.DataFrame({})\n",
    "df4e['Date']=date4e[:1]\n",
    "df4e['Author']=author4e[:1]\n",
    "df4e['Vertical']=vertical4e[:1]\n",
    "df4e['Healines']=headline4e[:1]\n",
    "df4e['Description']=description4e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb81d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b82907f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4f=[]\n",
    "author4f=[]\n",
    "vertical4f=[]\n",
    "headline4f=[]\n",
    "description4f=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4f.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author4f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical4f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6792383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4f=pd.DataFrame({})\n",
    "df4f['Date']=date4f[:1]\n",
    "df4f['Author']=author4f[:1]\n",
    "df4f['Vertical']=vertical4f[:1]\n",
    "df4f['Healines']=headline4f[:1]\n",
    "df4f['Description']=description4f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bc1cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aa57884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4g=[]\n",
    "author4g=[]\n",
    "vertical4g=[]\n",
    "headline4g=[]\n",
    "description4g=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4g.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author4g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|world']\")\n",
    "for i in ve:\n",
    "    vertical4g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c22a7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4g=pd.DataFrame({})\n",
    "df4g['Date']=date4g[:1]\n",
    "df4g['Author']=author4g[:1]\n",
    "df4g['Vertical']=vertical4g[:1]\n",
    "df4g['Healines']=headline4g[:1]\n",
    "df4g['Description']=description4g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367ffff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "217c2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4h=[]\n",
    "author4h=[]\n",
    "vertical4h=[]\n",
    "headline4h=[]\n",
    "description4h=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4h.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author4h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    vertical4h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f672fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4h=pd.DataFrame({})\n",
    "df4h['Date']=date4h[:1]\n",
    "df4h['Author']=author4h[:1]\n",
    "df4h['Vertical']=vertical4h[:1]\n",
    "df4h['Healines']=headline4h[:1]\n",
    "df4h['Description']=description4h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df99613c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "46812302",
   "metadata": {},
   "outputs": [],
   "source": [
    "date4i=[]\n",
    "author4i=[]\n",
    "vertical4i=[]\n",
    "headline4i=[]\n",
    "description4i=[]\n",
    "\n",
    "# scrapping details 4 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date4i.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author4i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|chennai']\")\n",
    "for i in ve:\n",
    "    vertical4i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline4i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description4i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "520e6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4i=pd.DataFrame({})\n",
    "df4i['Date']=date4i[:1]\n",
    "df4i['Author']=author4i[:1]\n",
    "df4i['Vertical']=vertical4i[:1]\n",
    "df4i['Healines']=headline4i[:1]\n",
    "df4i['Description']=description4i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c164f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68579bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "413016ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5=[]\n",
    "author5=[]\n",
    "vertical5=[]\n",
    "headline5=[]\n",
    "description5=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author5.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical5.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b584111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=pd.DataFrame({})\n",
    "df5['Date']=date5[:1]\n",
    "df5['Author']=author5[:1]\n",
    "df5['Vertical']=vertical5[:1]\n",
    "df5['Healines']=headline5[:1]\n",
    "df5['Description']=description5[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a770cf85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67a82e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5a=[]\n",
    "author5a=[]\n",
    "vertical5a=[]\n",
    "headline5a=[]\n",
    "description5a=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5a.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author5a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical5a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4bd20a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5a=pd.DataFrame({})\n",
    "df5a['Date']=date5a[:1]\n",
    "df5a['Author']=author5a[:1]\n",
    "df5a['Vertical']=vertical5a[:1]\n",
    "df5a['Healines']=headline5a[:1]\n",
    "df5a['Description']=description5a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa60bacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "67a5e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5b=[]\n",
    "author5b=[]\n",
    "vertical5b=[]\n",
    "headline5b=[]\n",
    "description5b=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5b.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author5b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical5b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a127bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5b=pd.DataFrame({})\n",
    "df5b['Date']=date5b[:1]\n",
    "df5b['Author']=author5b[:1]\n",
    "df5b['Vertical']=vertical5b[:1]\n",
    "df5b['Healines']=headline5b[:1]\n",
    "df5b['Description']=description5b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad8bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "083983f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5c=[]\n",
    "author5c=[]\n",
    "vertical5c=[]\n",
    "headline5c=[]\n",
    "description5c=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5c.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author5c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    vertical5c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "62a74bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5c=pd.DataFrame({})\n",
    "df5c['Date']=date5c[:1]\n",
    "df5c['Author']=author5c[:1]\n",
    "df5c['Vertical']=vertical5c[:1]\n",
    "df5c['Healines']=headline5c[:1]\n",
    "df5c['Description']=description5c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3028d2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6bcd7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5d=[]\n",
    "author5d=[]\n",
    "vertical5d=[]\n",
    "headline5d=[]\n",
    "description5d=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5d.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author5d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical5d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "59d45219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5d=pd.DataFrame({})\n",
    "df5d['Date']=date5d[:1]\n",
    "df5d['Author']=author5d[:1]\n",
    "df5d['Vertical']=vertical5d[:1]\n",
    "df5d['Healines']=headline5d[:1]\n",
    "df5d['Description']=description5d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f02b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e02825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5e=[]\n",
    "author5e=[]\n",
    "vertical5e=[]\n",
    "headline5e=[]\n",
    "description5e=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5e.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author5e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical5e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f6546088",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5e=pd.DataFrame({})\n",
    "df5e['Date']=date5e[:1]\n",
    "df5e['Author']=author5e[:1]\n",
    "df5e['Vertical']=vertical5e[:1]\n",
    "df5e['Healines']=headline5e[:1]\n",
    "df5e['Description']=description5e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5ef726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e907d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5f=[]\n",
    "author5f=[]\n",
    "vertical5f=[]\n",
    "headline5f=[]\n",
    "description5f=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5f.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author5f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical5f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "34822f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5f=pd.DataFrame({})\n",
    "df5f['Date']=date5f[:1]\n",
    "df5f['Author']=author5f[:1]\n",
    "df5f['Vertical']=vertical5f[:1]\n",
    "df5f['Healines']=headline5f[:1]\n",
    "df5f['Description']=description5f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52f24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "12ce8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5g=[]\n",
    "author5g=[]\n",
    "vertical5g=[]\n",
    "headline5g=[]\n",
    "description5g=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5g.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author5g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    vertical5g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "83c4d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5g=pd.DataFrame({})\n",
    "df5g['Date']=date5g[:1]\n",
    "df5g['Author']=author5g[:1]\n",
    "df5g['Vertical']=vertical5g[:1]\n",
    "df5g['Healines']=headline5g[:1]\n",
    "df5g['Description']=description5g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76918478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a5aa8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5h=[]\n",
    "author5h=[]\n",
    "vertical5h=[]\n",
    "headline5h=[]\n",
    "description5h=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5h.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author5h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical5h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dd24c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5h=pd.DataFrame({})\n",
    "df5h['Date']=date5h[:1]\n",
    "df5h['Author']=author5h[:1]\n",
    "df5h['Vertical']=vertical5h[:1]\n",
    "df5h['Healines']=headline5h[:1]\n",
    "df5h['Description']=description5h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd7f04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1b2af8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date5i=[]\n",
    "author5i=[]\n",
    "vertical5i=[]\n",
    "headline5i=[]\n",
    "description5i=[]\n",
    "\n",
    "# scrapping details 5 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date5i.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author5i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    vertical5i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline5i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description5i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "32291ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5i=pd.DataFrame({})\n",
    "df5i['Date']=date5i[:1]\n",
    "df5i['Author']=author5i[:1]\n",
    "df5i['Vertical']=vertical5i[:1]\n",
    "df5i['Healines']=headline5i[:1]\n",
    "df5i['Description']=description5i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c33476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2e6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3559013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6=[]\n",
    "author6=[]\n",
    "vertical6=[]\n",
    "headline6=[]\n",
    "description6=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author6.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical6.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "96473c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=pd.DataFrame({})\n",
    "df6['Date']=date6[:1]\n",
    "df6['Author']=author6[:1]\n",
    "df6['Vertical']=vertical6[:1]\n",
    "df6['Healines']=headline6[:1]\n",
    "df6['Description']=description6[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722042d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a03259f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6a=[]\n",
    "author6a=[]\n",
    "vertical6a=[]\n",
    "headline6a=[]\n",
    "description6a=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6a.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author6a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Business']\")\n",
    "for i in ve:\n",
    "    vertical6a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b988084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6a=pd.DataFrame({})\n",
    "df6a['Date']=date6a[:1]\n",
    "df6a['Author']=author6a[:1]\n",
    "df6a['Vertical']=vertical6a[:1]\n",
    "df6a['Healines']=headline6a[:1]\n",
    "df6a['Description']=description6a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2d890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9295963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6b=[]\n",
    "author6b=[]\n",
    "vertical6b=[]\n",
    "headline6b=[]\n",
    "description6b=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6b.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author6b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Business']\")\n",
    "for i in ve:\n",
    "    vertical6b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f29ce400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6b=pd.DataFrame({})\n",
    "df6b['Date']=date6b[:1]\n",
    "df6b['Author']=author6b[:1]\n",
    "df6b['Vertical']=vertical6b[:1]\n",
    "df6b['Healines']=headline6b[:1]\n",
    "df6b['Description']=description6b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af6cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9fbc8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6c=[]\n",
    "author6c=[]\n",
    "vertical6c=[]\n",
    "headline6c=[]\n",
    "description6c=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6c.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author6c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical6c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6c61ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6c=pd.DataFrame({})\n",
    "df6c['Date']=date6c[:1]\n",
    "df6c['Author']=author6c[:1]\n",
    "df6c['Vertical']=vertical6c[:1]\n",
    "df6c['Healines']=headline6c[:1]\n",
    "df6c['Description']=description6c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64299c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a87139d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6d=[]\n",
    "author6d=[]\n",
    "vertical6d=[]\n",
    "headline6d=[]\n",
    "description6d=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6d.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author6d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical6d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "59ad1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6d=pd.DataFrame({})\n",
    "df6d['Date']=date6d[:1]\n",
    "df6d['Author']=author6d[:1]\n",
    "df6d['Vertical']=vertical6d[:1]\n",
    "df6d['Healines']=headline6d[:1]\n",
    "df6d['Description']=description6d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66b9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f2bf35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6e=[]\n",
    "author6e=[]\n",
    "vertical6e=[]\n",
    "headline6e=[]\n",
    "description6e=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6e.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author6e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Business']\")\n",
    "for i in ve:\n",
    "    vertical6e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f992ee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6e=pd.DataFrame({})\n",
    "df6e['Date']=date6e[:1]\n",
    "df6e['Author']=author6e[:1]\n",
    "df6e['Vertical']=vertical6e[:1]\n",
    "df6e['Healines']=headline6e[:1]\n",
    "df6e['Description']=description6e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2d52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3830a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6f=[]\n",
    "author6f=[]\n",
    "vertical6f=[]\n",
    "headline6f=[]\n",
    "description6f=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6f.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author6f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Business']\")\n",
    "for i in ve:\n",
    "    vertical6f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "697864a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6f=pd.DataFrame({})\n",
    "df6f['Date']=date6f[:1]\n",
    "df6f['Author']=author6f[:1]\n",
    "df6f['Vertical']=vertical6f[:1]\n",
    "df6f['Healines']=headline6f[:1]\n",
    "df6f['Description']=description6f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaed061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f6710e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6g=[]\n",
    "author6g=[]\n",
    "vertical6g=[]\n",
    "headline6g=[]\n",
    "description6g=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6g.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author6g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|noida']\")\n",
    "for i in ve:\n",
    "    vertical6g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "361c7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6g=pd.DataFrame({})\n",
    "df6g['Date']=date6g[:1]\n",
    "df6g['Author']=author6g[:1]\n",
    "df6g['Vertical']=vertical6g[:1]\n",
    "df6g['Healines']=headline6g[:1]\n",
    "df6g['Description']=description6g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2e827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8ac3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6h=[]\n",
    "author6h=[]\n",
    "vertical6h=[]\n",
    "headline6h=[]\n",
    "description6h=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6h.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author6h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical6h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c1ce6042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6h=pd.DataFrame({})\n",
    "df6h['Date']=date6h[:1]\n",
    "df6h['Author']=author6h[:1]\n",
    "df6h['Vertical']=vertical6h[:1]\n",
    "df6h['Healines']=headline6h[:1]\n",
    "df6h['Description']=description6h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71617ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bcaca99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date6i=[]\n",
    "author6i=[]\n",
    "vertical6i=[]\n",
    "headline6i=[]\n",
    "description6i=[]\n",
    "\n",
    "# scrapping details 6 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date6i.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author6i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|India Business']\")\n",
    "for i in ve:\n",
    "    vertical6i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline6i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description6i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6c4550ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6i=pd.DataFrame({})\n",
    "df6i['Date']=date6i[:1]\n",
    "df6i['Author']=author6i[:1]\n",
    "df6i['Vertical']=vertical6i[:1]\n",
    "df6i['Healines']=headline6i[:1]\n",
    "df6i['Description']=description6i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcda37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca236a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a60a8ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7=[]\n",
    "author7=[]\n",
    "vertical7=[]\n",
    "headline7=[]\n",
    "description7=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author7.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|noida']\")\n",
    "for i in ve:\n",
    "    vertical7.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e1d775b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=pd.DataFrame({})\n",
    "df7['Date']=date7[:1]\n",
    "df7['Author']=author7[:1]\n",
    "df7['Vertical']=vertical7[:1]\n",
    "df7['Healines']=headline7[:1]\n",
    "df7['Description']=description7[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4158644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f81a93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7a=[]\n",
    "author7a=[]\n",
    "vertical7a=[]\n",
    "headline7a=[]\n",
    "description7a=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7a.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author7a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|chandigarh']\")\n",
    "for i in ve:\n",
    "    vertical7a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "60b9b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7a=pd.DataFrame({})\n",
    "df7a['Date']=date7a[:1]\n",
    "df7a['Author']=author7a[:1]\n",
    "df7a['Vertical']=vertical7a[:1]\n",
    "df7a['Healines']=headline7a[:1]\n",
    "df7a['Description']=description7a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c9425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8cbfdc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7b=[]\n",
    "author7b=[]\n",
    "vertical7b=[]\n",
    "headline7b=[]\n",
    "description7b=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7b.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author7b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    vertical7b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6009bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7b=pd.DataFrame({})\n",
    "df7b['Date']=date7b[:1]\n",
    "df7b['Author']=author7b[:1]\n",
    "df7b['Vertical']=vertical7b[:1]\n",
    "df7b['Healines']=headline7b[:1]\n",
    "df7b['Description']=description7b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e39267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "549520d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7c=[]\n",
    "author7c=[]\n",
    "vertical7c=[]\n",
    "headline7c=[]\n",
    "description7c=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7c.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author7c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|chennai']\")\n",
    "for i in ve:\n",
    "    vertical7c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "726200fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7c=pd.DataFrame({})\n",
    "df7c['Date']=date7c[:1]\n",
    "df7c['Author']=author7c[:1]\n",
    "df7c['Vertical']=vertical7c[:1]\n",
    "df7c['Healines']=headline7c[:1]\n",
    "df7c['Description']=description7c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ad3adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "35ad59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7d=[]\n",
    "author7d=[]\n",
    "vertical7d=[]\n",
    "headline7d=[]\n",
    "description7d=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7d.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author7d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical7d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e541cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7d=pd.DataFrame({})\n",
    "df7d['Date']=date7d[:1]\n",
    "df7d['Author']=author7d[:1]\n",
    "df7d['Vertical']=vertical7d[:1]\n",
    "df7d['Healines']=headline7d[:1]\n",
    "df7d['Description']=description7d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e076848b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8ee842a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7e=[]\n",
    "author7e=[]\n",
    "vertical7e=[]\n",
    "headline7e=[]\n",
    "description7e=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7e.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author7e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|coimbatore']\")\n",
    "for i in ve:\n",
    "    vertical7e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b2796e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7e=pd.DataFrame({})\n",
    "df7e['Date']=date7e[:1]\n",
    "df7e['Author']=author7e[:1]\n",
    "df7e['Vertical']=vertical7e[:1]\n",
    "df7e['Healines']=headline7e[:1]\n",
    "df7e['Description']=description7e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89ee41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6918bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7f=[]\n",
    "author7f=[]\n",
    "vertical7f=[]\n",
    "headline7f=[]\n",
    "description7f=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7f.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author7f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical7f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dd025d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7f=pd.DataFrame({})\n",
    "df7f['Date']=date7f[:1]\n",
    "df7f['Author']=author7f[:1]\n",
    "df7f['Vertical']=vertical7f[:1]\n",
    "df7f['Healines']=headline7f[:1]\n",
    "df7f['Description']=description7f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2269cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6e94149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7g=[]\n",
    "author7g=[]\n",
    "vertical7g=[]\n",
    "headline7g=[]\n",
    "description7g=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7g.append(i.text)\n",
    "    \n",
    "  \n",
    "       \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author7g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical7g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8e92a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7g=pd.DataFrame({})\n",
    "df7g['Date']=date7g[:1]\n",
    "df7g['Author']=author7g[:1]\n",
    "df7g['Vertical']=vertical7g[:1]\n",
    "df7g['Healines']=headline7g[:1]\n",
    "df7g['Description']=description7g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644c3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ffab6e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7h=[]\n",
    "author7h=[]\n",
    "vertical7h=[]\n",
    "headline7h=[]\n",
    "description7h=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author7h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical7h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2172df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7h=pd.DataFrame({})\n",
    "df7h['Date']=date7h[:1]\n",
    "df7h['Author']=author7h[:1]\n",
    "df7h['Vertical']=vertical7h[:1]\n",
    "df7h['Healines']=headline7h[:1]\n",
    "df7h['Description']=description7h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44eda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0e2d0c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date7i=[]\n",
    "author7i=[]\n",
    "vertical7i=[]\n",
    "headline7i=[]\n",
    "description7i=[]\n",
    "\n",
    "# scrapping details 7 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date7i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author7i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|City']\")\n",
    "for i in ve:\n",
    "    vertical7i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline7i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description7i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d0d5e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7i=pd.DataFrame({})\n",
    "df7i['Date']=date7i[:1]\n",
    "df7i['Author']=author7i[:1]\n",
    "df7i['Vertical']=vertical7i[:1]\n",
    "df7i['Healines']=headline7i[:1]\n",
    "df7i['Description']=description7i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46e5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8c455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f51a9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8=[]\n",
    "author8=[]\n",
    "vertical8=[]\n",
    "headline8=[]\n",
    "description8=[]\n",
    "\n",
    "# scrapping details  july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author8.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|sports']\")\n",
    "for i in ve:\n",
    "    vertical8.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6e5d2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8=pd.DataFrame({})\n",
    "df8['Date']=date8[:1]\n",
    "df8['Author']=author8[:1]\n",
    "df8['Vertical']=vertical8[:1]\n",
    "df8['Healines']=headline8[:1]\n",
    "df8['Description']=description8[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34cc598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9c48b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8a=[]\n",
    "author8a=[]\n",
    "vertical8a=[]\n",
    "headline8a=[]\n",
    "description8a=[]\n",
    "\n",
    "# scrapping details  july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author8a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical8a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "37c344f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8a=pd.DataFrame({})\n",
    "df8a['Date']=date8a[:1]\n",
    "df8a['Author']=author8a[:1]\n",
    "df8a['Vertical']=vertical8a[:1]\n",
    "df8a['Healines']=headline8a[:1]\n",
    "df8a['Description']=description8a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd2ca3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9d2a7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8b=[]\n",
    "author8b=[]\n",
    "vertical8b=[]\n",
    "headline8b=[]\n",
    "description8b=[]\n",
    "\n",
    "# scrapping details  july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author8b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical8b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "32445468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8b=pd.DataFrame({})\n",
    "df8b['Date']=date8b[:1]\n",
    "df8b['Author']=author8b[:1]\n",
    "df8b['Vertical']=vertical8b[:1]\n",
    "df8b['Healines']=headline8b[:1]\n",
    "df8b['Description']=description8b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac82b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "99466a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8c=[]\n",
    "author8c=[]\n",
    "vertical8c=[]\n",
    "headline8c=[]\n",
    "description8c=[]\n",
    "\n",
    "# scrapping details  july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author8c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|events']\")\n",
    "for i in ve:\n",
    "    vertical8c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1a7af447",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8c=pd.DataFrame({})\n",
    "df8c['Date']=date8c[:1]\n",
    "df8c['Author']=author8c[:1]\n",
    "df8c['Vertical']=vertical8c[:1]\n",
    "df8c['Healines']=headline8c[:1]\n",
    "df8c['Description']=description8c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b204ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ea03ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8d=[]\n",
    "author8d=[]\n",
    "vertical8d=[]\n",
    "headline8d=[]\n",
    "description8d=[]\n",
    "\n",
    "# scrapping details  july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author8d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ajmer']\")\n",
    "for i in ve:\n",
    "    vertical8d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d1c91c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8d=pd.DataFrame({})\n",
    "df8d['Date']=date8d[:1]\n",
    "df8d['Author']=author8d[:1]\n",
    "df8d['Vertical']=vertical8d[:1]\n",
    "df8d['Healines']=headline8d[:1]\n",
    "df8d['Description']=description8d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed5c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3588cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8e=[]\n",
    "author8e=[]\n",
    "vertical8e=[]\n",
    "headline8e=[]\n",
    "description8e=[]\n",
    "\n",
    "# scrapping details  july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author8e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical8e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "04ebdc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8e=pd.DataFrame({})\n",
    "df8e['Date']=date8e[:1]\n",
    "df8e['Author']=author8e[:1]\n",
    "df8e['Vertical']=vertical8e[:1]\n",
    "df8e['Healines']=headline8e[:1]\n",
    "df8e['Description']=description8e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54083126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9cf399d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8f=[]\n",
    "author8f=[]\n",
    "vertical8f=[]\n",
    "headline8f=[]\n",
    "description8f=[]\n",
    "\n",
    "# scrapping details  july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author8f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical8f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "75653cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8f=pd.DataFrame({})\n",
    "df8f['Date']=date8f[:1]\n",
    "df8f['Author']=author8f[:1]\n",
    "df8f['Vertical']=vertical8f[:1]\n",
    "df8f['Healines']=headline8f[:1]\n",
    "df8f['Description']=description8f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe454d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5d18b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8g=[]\n",
    "author8g=[]\n",
    "vertical8g=[]\n",
    "headline8g=[]\n",
    "description8g=[]\n",
    "\n",
    "# scrapping details  july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author8g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Rest of World']\")\n",
    "for i in ve:\n",
    "    vertical8g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8111899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8g=pd.DataFrame({})\n",
    "df8g['Date']=date8g[:1]\n",
    "df8g['Author']=author8g[:1]\n",
    "df8g['Vertical']=vertical8g[:1]\n",
    "df8g['Healines']=headline8g[:1]\n",
    "df8g['Description']=description8g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad9d2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bf74184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8h=[]\n",
    "author8h=[]\n",
    "vertical8h=[]\n",
    "headline8h=[]\n",
    "description8h=[]\n",
    "\n",
    "# scrapping details  july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author8h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical8h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e05f3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8h=pd.DataFrame({})\n",
    "df8h['Date']=date8h[:1]\n",
    "df8h['Author']=author8h[:1]\n",
    "df8h['Vertical']=vertical8h[:1]\n",
    "df8h['Healines']=headline8h[:1]\n",
    "df8h['Description']=description8h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f31ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "30ce73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date8i=[]\n",
    "author8i=[]\n",
    "vertical8i=[]\n",
    "headline8i=[]\n",
    "description8i=[]\n",
    "\n",
    "# scrapping details 8 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date8i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author8i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical8i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline8i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description8i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "251f139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8i=pd.DataFrame({})\n",
    "df8i['Date']=date8i[:1]\n",
    "df8i['Author']=author8i[:1]\n",
    "df8i['Vertical']=vertical8i[:1]\n",
    "df8i['Healines']=headline8i[:1]\n",
    "df8i['Description']=description8i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989943a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be2c2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "bd14a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9=[]\n",
    "author9=[]\n",
    "vertical9=[]\n",
    "headline9=[]\n",
    "description9=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author9.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|noida']\")\n",
    "for i in ve:\n",
    "    vertical9.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "68a0c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9=pd.DataFrame({})\n",
    "df9['Date']=date9[:1]\n",
    "df9['Author']=author9[:1]\n",
    "df9['Vertical']=vertical9[:1]\n",
    "df9['Healines']=headline9[:1]\n",
    "df9['Description']=description9[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12ea19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7af3954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9a=[]\n",
    "author9a=[]\n",
    "vertical9a=[]\n",
    "headline9a=[]\n",
    "description9a=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author9a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ghaziabad']\")\n",
    "for i in ve:\n",
    "    vertical9a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "5c425cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9a=pd.DataFrame({})\n",
    "df9a['Date']=date9a[:1]\n",
    "df9a['Author']=author9a[:1]\n",
    "df9a['Vertical']=vertical9a[:1]\n",
    "df9a['Healines']=headline9a[:1]\n",
    "df9a['Description']=description9a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655a470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "79a6d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9b=[]\n",
    "author9b=[]\n",
    "vertical9b=[]\n",
    "headline9b=[]\n",
    "description9b=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author9b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|noida']\")\n",
    "for i in ve:\n",
    "    vertical9b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9efab401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9b=pd.DataFrame({})\n",
    "df9b['Date']=date9b[:1]\n",
    "df9b['Author']=author9b[:1]\n",
    "df9b['Vertical']=vertical9b[:1]\n",
    "df9b['Healines']=headline9b[:1]\n",
    "df9b['Description']=description9b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419880f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "706e8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9c=[]\n",
    "author9c=[]\n",
    "vertical9c=[]\n",
    "headline9c=[]\n",
    "description9c=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author9c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    vertical9c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7e960bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9c=pd.DataFrame({})\n",
    "df9c['Date']=date9c[:1]\n",
    "df9c['Author']=author9c[:1]\n",
    "df9c['Vertical']=vertical9c[:1]\n",
    "df9c['Healines']=headline9c[:1]\n",
    "df9c['Description']=description9c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718e12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "800605da",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9d=[]\n",
    "author9d=[]\n",
    "vertical9d=[]\n",
    "headline9d=[]\n",
    "description9d=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author9d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical9d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "877f2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9d=pd.DataFrame({})\n",
    "df9d['Date']=date9d[:1]\n",
    "df9d['Author']=author9d[:1]\n",
    "df9d['Vertical']=vertical9d[:1]\n",
    "df9d['Healines']=headline9d[:1]\n",
    "df9d['Description']=description9d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f57020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6cc36a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9e=[]\n",
    "author9e=[]\n",
    "vertical9e=[]\n",
    "headline9e=[]\n",
    "description9e=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author9e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|agra']\")\n",
    "for i in ve:\n",
    "    vertical9e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b64d5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9e=pd.DataFrame({})\n",
    "df9e['Date']=date9e[:1]\n",
    "df9e['Author']=author9e[:1]\n",
    "df9e['Vertical']=vertical9e[:1]\n",
    "df9e['Healines']=headline9e[:1]\n",
    "df9e['Description']=description9e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be41ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e907fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9f=[]\n",
    "author9f=[]\n",
    "vertical9f=[]\n",
    "headline9f=[]\n",
    "description9f=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author9f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical9f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "5eddee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9f=pd.DataFrame({})\n",
    "df9f['Date']=date9f[:1]\n",
    "df9f['Author']=author9f[:1]\n",
    "df9f['Vertical']=vertical9f[:1]\n",
    "df9f['Healines']=headline9f[:1]\n",
    "df9f['Description']=description9f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea7666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d973743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9g=[]\n",
    "author9g=[]\n",
    "vertical9g=[]\n",
    "headline9g=[]\n",
    "description9g=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author9g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical9g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c096d652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9g=pd.DataFrame({})\n",
    "df9g['Date']=date9g[:1]\n",
    "df9g['Author']=author9g[:1]\n",
    "df9g['Vertical']=vertical9g[:1]\n",
    "df9g['Healines']=headline9g[:1]\n",
    "df9g['Description']=description9g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1737d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6d348d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9h=[]\n",
    "author9h=[]\n",
    "vertical9h=[]\n",
    "headline9h=[]\n",
    "description9h=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author9h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|arunachal elections']\")\n",
    "for i in ve:\n",
    "    vertical9h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "be61b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9h=pd.DataFrame({})\n",
    "df9h['Date']=date9h[:1]\n",
    "df9h['Author']=author9h[:1]\n",
    "df9h['Vertical']=vertical9h[:1]\n",
    "df9h['Healines']=headline9h[:1]\n",
    "df9h['Description']=description9h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98676a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "cb975e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "date9i=[]\n",
    "author9i=[]\n",
    "vertical9i=[]\n",
    "headline9i=[]\n",
    "description9i=[]\n",
    "\n",
    "# scrapping details 9 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date9i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author9i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical9i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline9i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description9i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a7dc154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9i=pd.DataFrame({})\n",
    "df9i['Date']=date9i[:1]\n",
    "df9i['Author']=author9i[:1]\n",
    "df9i['Vertical']=vertical9i[:1]\n",
    "df9i['Healines']=headline9i[:1]\n",
    "df9i['Description']=description9i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899ed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55eec76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "0aab2c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10=[]\n",
    "author10=[]\n",
    "vertical10=[]\n",
    "headline10=[]\n",
    "description10=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author10.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|International Business']\")\n",
    "for i in ve:\n",
    "    vertical10.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "7e522b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10=pd.DataFrame({})\n",
    "df10['Date']=date10[:1]\n",
    "df10['Author']=author10[:1]\n",
    "df10['Vertical']=vertical10[:1]\n",
    "df10['Healines']=headline10[:1]\n",
    "df10['Description']=description10[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0fac9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "88bfa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10a=[]\n",
    "author10a=[]\n",
    "vertical10a=[]\n",
    "headline10a=[]\n",
    "description10a=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author10a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical10a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1d2f5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10a=pd.DataFrame({})\n",
    "df10a['Date']=date10a[:1]\n",
    "df10a['Author']=author10a[:1]\n",
    "df10a['Vertical']=vertical10a[:1]\n",
    "df10a['Healines']=headline10a[:1]\n",
    "df10a['Description']=description10a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ffebcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b3e49494",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10b=[]\n",
    "author10b=[]\n",
    "vertical10b=[]\n",
    "headline10b=[]\n",
    "description10b=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author10b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|amritsar']\")\n",
    "for i in ve:\n",
    "    vertical10b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c0b970b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10b=pd.DataFrame({})\n",
    "df10b['Date']=date10b[:1]\n",
    "df10b['Author']=author10b[:1]\n",
    "df10b['Vertical']=vertical10b[:1]\n",
    "df10b['Healines']=headline10b[:1]\n",
    "df10b['Description']=description10b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eefca0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "3ffc6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10c=[]\n",
    "author10c=[]\n",
    "vertical10c=[]\n",
    "headline10c=[]\n",
    "description10c=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author10c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical10c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7368928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10c=pd.DataFrame({})\n",
    "df10c['Date']=date10c[:1]\n",
    "df10c['Author']=author10c[:1]\n",
    "df10c['Vertical']=vertical10c[:1]\n",
    "df10c['Healines']=headline10c[:1]\n",
    "df10c['Description']=description10c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e189f127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2a7d37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10d=[]\n",
    "author10d=[]\n",
    "vertical10d=[]\n",
    "headline10d=[]\n",
    "description10d=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author10d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical10d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9e9e1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10d=pd.DataFrame({})\n",
    "df10d['Date']=date10d[:1]\n",
    "df10d['Author']=author10d[:1]\n",
    "df10d['Vertical']=vertical10d[:1]\n",
    "df10d['Healines']=headline10d[:1]\n",
    "df10d['Description']=description10d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383279b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "57049054",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10e=[]\n",
    "author10e=[]\n",
    "vertical10e=[]\n",
    "headline10e=[]\n",
    "description10e=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author10e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|indore']\")\n",
    "for i in ve:\n",
    "    vertical10e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b6a24ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10e=pd.DataFrame({})\n",
    "df10e['Date']=date10e[:1]\n",
    "df10e['Author']=author10e[:1]\n",
    "df10e['Vertical']=vertical10e[:1]\n",
    "df10e['Healines']=headline10e[:1]\n",
    "df10e['Description']=description10e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa2b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6520857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10f=[]\n",
    "author10f=[]\n",
    "vertical10f=[]\n",
    "headline10f=[]\n",
    "description10f=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author10f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    vertical10f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "573f0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10f=pd.DataFrame({})\n",
    "df10f['Date']=date10f[:1]\n",
    "df10f['Author']=author10f[:1]\n",
    "df10f['Vertical']=vertical10f[:1]\n",
    "df10f['Healines']=headline10f[:1]\n",
    "df10f['Description']=description10f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a1a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0cb0b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10g=[]\n",
    "author10g=[]\n",
    "vertical10g=[]\n",
    "headline10g=[]\n",
    "description10g=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author10g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical10g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8ebb10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10g=pd.DataFrame({})\n",
    "df10g['Date']=date10g[:1]\n",
    "df10g['Author']=author10g[:1]\n",
    "df10g['Vertical']=vertical10g[:1]\n",
    "df10g['Healines']=headline10g[:1]\n",
    "df10g['Description']=description10g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e2b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1bbe331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10h=[]\n",
    "author10h=[]\n",
    "vertical10h=[]\n",
    "headline10h=[]\n",
    "description10h=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author10h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical10h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1d3cf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10h=pd.DataFrame({})\n",
    "df10h['Date']=date10h[:1]\n",
    "df10h['Author']=author10h[:1]\n",
    "df10h['Vertical']=vertical10h[:1]\n",
    "df10h['Healines']=headline10h[:1]\n",
    "df10h['Description']=description10h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c973d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "73f2b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "date10i=[]\n",
    "author10i=[]\n",
    "vertical10i=[]\n",
    "headline10i=[]\n",
    "description10i=[]\n",
    "\n",
    "# scrapping details 10 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date10i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author10i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|events']\")\n",
    "for i in ve:\n",
    "    vertical10i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline10i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description10i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "72cd818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10i=pd.DataFrame({})\n",
    "df10i['Date']=date10i[:1]\n",
    "df10i['Author']=author10i[:1]\n",
    "df10i['Vertical']=vertical10i[:1]\n",
    "df10i['Healines']=headline10i[:1]\n",
    "df10i['Description']=description10i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264a215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02678a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "4f0aba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11=[]\n",
    "author11=[]\n",
    "vertical11=[]\n",
    "headline11=[]\n",
    "description11=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author11.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    vertical11.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "63e0b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11=pd.DataFrame({})\n",
    "df11['Date']=date11[:1]\n",
    "df11['Author']=author11[:1]\n",
    "df11['Vertical']=vertical11[:1]\n",
    "df11['Healines']=headline11[:1]\n",
    "df11['Description']=description11[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5d5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "16551759",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11a=[]\n",
    "author11a=[]\n",
    "vertical11a=[]\n",
    "headline11a=[]\n",
    "description11a=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author11a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|bol daal']\")\n",
    "for i in ve:\n",
    "    vertical11a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "320c925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11a=pd.DataFrame({})\n",
    "df11a['Date']=date11a[:1]\n",
    "df11a['Author']=author11a[:1]\n",
    "df11a['Vertical']=vertical11a[:1]\n",
    "df11a['Healines']=headline11a[:1]\n",
    "df11a['Description']=description11a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518fd73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c3787b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11b=[]\n",
    "author11b=[]\n",
    "vertical11b=[]\n",
    "headline11b=[]\n",
    "description11b=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author11b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical11b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f2a7e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11b=pd.DataFrame({})\n",
    "df11b['Date']=date11b[:1]\n",
    "df11b['Author']=author11b[:1]\n",
    "df11b['Vertical']=vertical11b[:1]\n",
    "df11b['Healines']=headline11b[:1]\n",
    "df11b['Description']=description11b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429c5ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "8ac88dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11c=[]\n",
    "author11c=[]\n",
    "vertical11c=[]\n",
    "headline11c=[]\n",
    "description11c=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author11c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|kochi']\")\n",
    "for i in ve:\n",
    "    vertical11c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "edfe4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11c=pd.DataFrame({})\n",
    "df11c['Date']=date11c[:1]\n",
    "df11c['Author']=author11c[:1]\n",
    "df11c['Vertical']=vertical11c[:1]\n",
    "df11c['Healines']=headline11c[:1]\n",
    "df11c['Description']=description11c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e752a3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "23f8478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11d=[]\n",
    "author11d=[]\n",
    "vertical11d=[]\n",
    "headline11d=[]\n",
    "description11d=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author11d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    vertical11d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "a4f47906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11d=pd.DataFrame({})\n",
    "df11d['Date']=date11d[:1]\n",
    "df11d['Author']=author11d[:1]\n",
    "df11d['Vertical']=vertical11d[:1]\n",
    "df11d['Healines']=headline11d[:1]\n",
    "df11d['Description']=description11d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf5305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "0ef1944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11e=[]\n",
    "author11e=[]\n",
    "vertical11e=[]\n",
    "headline11e=[]\n",
    "description11e=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author11e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    vertical11e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "1e08717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11e=pd.DataFrame({})\n",
    "df11e['Date']=date11e[:1]\n",
    "df11e['Author']=author11e[:1]\n",
    "df11e['Vertical']=vertical11e[:1]\n",
    "df11e['Healines']=headline11e[:1]\n",
    "df11e['Description']=description11e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669f386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "0f330573",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11f=[]\n",
    "author11f=[]\n",
    "vertical11f=[]\n",
    "headline11f=[]\n",
    "description11f=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author11f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical11f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "75fd9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11f=pd.DataFrame({})\n",
    "df11f['Date']=date11f[:1]\n",
    "df11f['Author']=author11f[:1]\n",
    "df11f['Vertical']=vertical11f[:1]\n",
    "df11f['Healines']=headline11f[:1]\n",
    "df11f['Description']=description11f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97250cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "61316705",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11g=[]\n",
    "author11g=[]\n",
    "vertical11g=[]\n",
    "headline11g=[]\n",
    "description11g=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author11g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical11g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5a8c68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11g=pd.DataFrame({})\n",
    "df11g['Date']=date11g[:1]\n",
    "df11g['Author']=author11g[:1]\n",
    "df11g['Vertical']=vertical11g[:1]\n",
    "df11g['Healines']=headline11g[:1]\n",
    "df11g['Description']=description11g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176302c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "926dee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11h=[]\n",
    "author11h=[]\n",
    "vertical11h=[]\n",
    "headline11h=[]\n",
    "description11h=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author11h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical11h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "49138242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11h=pd.DataFrame({})\n",
    "df11h['Date']=date11h[:1]\n",
    "df11h['Author']=author11h[:1]\n",
    "df11h['Vertical']=vertical11h[:1]\n",
    "df11h['Healines']=headline11h[:1]\n",
    "df11h['Description']=description11h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137d8c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "3cf73d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date11i=[]\n",
    "author11i=[]\n",
    "vertical11i=[]\n",
    "headline11i=[]\n",
    "description11i=[]\n",
    "\n",
    "# scrapping details 11 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date11i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author11i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical11i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline11i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description11i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "5f05c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11i=pd.DataFrame({})\n",
    "df11i['Date']=date11i[:1]\n",
    "df11i['Author']=author11i[:1]\n",
    "df11i['Vertical']=vertical11i[:1]\n",
    "df11i['Healines']=headline11i[:1]\n",
    "df11i['Description']=description11i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aca36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaedd85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ed75ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12=[]\n",
    "author12=[]\n",
    "vertical12=[]\n",
    "headline12=[]\n",
    "description12=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author12.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ahmedabad']\")\n",
    "for i in ve:\n",
    "    vertical12.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "53178dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12=pd.DataFrame({})\n",
    "df12['Date']=date12[:1]\n",
    "df12['Author']=author12[:1]\n",
    "df12['Vertical']=vertical12[:1]\n",
    "df12['Healines']=headline12[:1]\n",
    "df12['Description']=description12[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b621bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "750c3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12a=[]\n",
    "author12a=[]\n",
    "vertical12a=[]\n",
    "headline12a=[]\n",
    "description12a=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author12a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical12a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "3a1c7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12a=pd.DataFrame({})\n",
    "df12a['Date']=date12a[:1]\n",
    "df12a['Author']=author12a[:1]\n",
    "df12a['Vertical']=vertical12a[:1]\n",
    "df12a['Healines']=headline12a[:1]\n",
    "df12a['Description']=description12a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd93494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "f0204c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12b=[]\n",
    "author12b=[]\n",
    "vertical12b=[]\n",
    "headline12b=[]\n",
    "description12b=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author12b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ranchi']\")\n",
    "for i in ve:\n",
    "    vertical12b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "7a814c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12b=pd.DataFrame({})\n",
    "df12b['Date']=date12b[:1]\n",
    "df12b['Author']=author12b[:1]\n",
    "df12b['Vertical']=vertical12b[:1]\n",
    "df12b['Healines']=headline12b[:1]\n",
    "df12b['Description']=description12b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce592f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c48e96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12c=[]\n",
    "author12c=[]\n",
    "vertical12c=[]\n",
    "headline12c=[]\n",
    "description12c=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author12c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical12c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "4d6538e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12c=pd.DataFrame({})\n",
    "df12c['Date']=date12c[:1]\n",
    "df12c['Author']=author12c[:1]\n",
    "df12c['Vertical']=vertical12c[:1]\n",
    "df12c['Healines']=headline12c[:1]\n",
    "df12c['Description']=description12c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee64338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "18ef063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12d=[]\n",
    "author12d=[]\n",
    "vertical12d=[]\n",
    "headline12d=[]\n",
    "description12d=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author12d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    vertical12d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "017fb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12d=pd.DataFrame({})\n",
    "df12d['Date']=date12d[:1]\n",
    "df12d['Author']=author12d[:1]\n",
    "df12d['Vertical']=vertical12d[:1]\n",
    "df12d['Healines']=headline12d[:1]\n",
    "df12d['Description']=description12d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb2533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "5eed2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12e=[]\n",
    "author12e=[]\n",
    "vertical12e=[]\n",
    "headline12e=[]\n",
    "description12e=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author12e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical12e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "99e77f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12e=pd.DataFrame({})\n",
    "df12e['Date']=date12e[:1]\n",
    "df12e['Author']=author12e[:1]\n",
    "df12e['Vertical']=vertical12e[:1]\n",
    "df12e['Healines']=headline12e[:1]\n",
    "df12e['Description']=description12e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e8e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "109b5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12f=[]\n",
    "author12f=[]\n",
    "vertical12f=[]\n",
    "headline12f=[]\n",
    "description12f=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author12f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical12f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "cb112b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12f=pd.DataFrame({})\n",
    "df12f['Date']=date12f[:1]\n",
    "df12f['Author']=author12f[:1]\n",
    "df12f['Vertical']=vertical12f[:1]\n",
    "df12f['Healines']=headline12f[:1]\n",
    "df12f['Description']=description12f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be1979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "70fddc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12g=[]\n",
    "author12g=[]\n",
    "vertical12g=[]\n",
    "headline12g=[]\n",
    "description12g=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author12g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical12g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "da25e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12g=pd.DataFrame({})\n",
    "df12g['Date']=date12g[:1]\n",
    "df12g['Author']=author12g[:1]\n",
    "df12g['Vertical']=vertical12g[:1]\n",
    "df12g['Healines']=headline12g[:1]\n",
    "df12g['Description']=description12g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93ebc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "c19c7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12h=[]\n",
    "author12h=[]\n",
    "vertical12h=[]\n",
    "headline12h=[]\n",
    "description12h=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author12h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|jamshedpur']\")\n",
    "for i in ve:\n",
    "    vertical12h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "4bcdad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12h=pd.DataFrame({})\n",
    "df12h['Date']=date12h[:1]\n",
    "df12h['Author']=author12h[:1]\n",
    "df12h['Vertical']=vertical12h[:1]\n",
    "df12h['Healines']=headline12h[:1]\n",
    "df12h['Description']=description12h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39434b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "7a38d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "date12i=[]\n",
    "author12i=[]\n",
    "vertical12i=[]\n",
    "headline12i=[]\n",
    "description12i=[]\n",
    "\n",
    "# scrapping details 12 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date12i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author12i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|amaravati']\")\n",
    "for i in ve:\n",
    "    vertical12i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline12i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description12i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "fb4b81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12i=pd.DataFrame({})\n",
    "df12i['Date']=date12i[:1]\n",
    "df12i['Author']=author12i[:1]\n",
    "df12i['Vertical']=vertical12i[:1]\n",
    "df12i['Healines']=headline12i[:1]\n",
    "df12i['Description']=description12i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bdd0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "658d5de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13=[]\n",
    "author13=[]\n",
    "vertical13=[]\n",
    "headline13=[]\n",
    "description13=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author13.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    vertical13.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "173de70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13=pd.DataFrame({})\n",
    "df13['Date']=date13[:1]\n",
    "df13['Author']=author13[:1]\n",
    "df13['Vertical']=vertical13[:1]\n",
    "df13['Healines']=headline13[:1]\n",
    "df13['Description']=description13[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034ee1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "fb731242",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13a=[]\n",
    "author13a=[]\n",
    "vertical13a=[]\n",
    "headline13a=[]\n",
    "description13a=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author13a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|pollution news']\")\n",
    "for i in ve:\n",
    "    vertical13a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "4c01daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13a=pd.DataFrame({})\n",
    "df13a['Date']=date13a[:1]\n",
    "df13a['Author']=author13a[:1]\n",
    "df13a['Vertical']=vertical13a[:1]\n",
    "df13a['Healines']=headline13a[:1]\n",
    "df13a['Description']=description13a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfaa5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "8a8b90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13b=[]\n",
    "author13b=[]\n",
    "vertical13b=[]\n",
    "headline13b=[]\n",
    "description13b=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author13b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    vertical13b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "9efe79fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13b=pd.DataFrame({})\n",
    "df13b['Date']=date13b[:1]\n",
    "df13b['Author']=author13b[:1]\n",
    "df13b['Vertical']=vertical13b[:1]\n",
    "df13b['Healines']=headline13b[:1]\n",
    "df13b['Description']=description13b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b30862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "e6cdf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13c=[]\n",
    "author13c=[]\n",
    "vertical13c=[]\n",
    "headline13c=[]\n",
    "description13c=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author13c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|gurgaon']\")\n",
    "for i in ve:\n",
    "    vertical13c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "912c85ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13c=pd.DataFrame({})\n",
    "df13c['Date']=date13c[:1]\n",
    "df13c['Author']=author13c[:1]\n",
    "df13c['Vertical']=vertical13c[:1]\n",
    "df13c['Healines']=headline13c[:1]\n",
    "df13c['Description']=description13c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7691c7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "c81757a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13d=[]\n",
    "author13d=[]\n",
    "vertical13d=[]\n",
    "headline13d=[]\n",
    "description13d=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author13d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical13d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e54653e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13d=pd.DataFrame({})\n",
    "df13d['Date']=date13d[:1]\n",
    "df13d['Author']=author13d[:1]\n",
    "df13d['Vertical']=vertical13d[:1]\n",
    "df13d['Healines']=headline13d[:1]\n",
    "df13d['Description']=description13d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8ff7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "2e37fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13e=[]\n",
    "author13e=[]\n",
    "vertical13e=[]\n",
    "headline13e=[]\n",
    "description13e=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author13e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|trichy']\")\n",
    "for i in ve:\n",
    "    vertical13e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "cad11bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13e=pd.DataFrame({})\n",
    "df13e['Date']=date13e[:1]\n",
    "df13e['Author']=author13e[:1]\n",
    "df13e['Vertical']=vertical13e[:1]\n",
    "df13e['Healines']=headline13e[:1]\n",
    "df13e['Description']=description13e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c759cec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b6b312cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13f=[]\n",
    "author13f=[]\n",
    "vertical13f=[]\n",
    "headline13f=[]\n",
    "description13f=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author13f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical13f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "22358c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13f=pd.DataFrame({})\n",
    "df13f['Date']=date13f[:1]\n",
    "df13f['Author']=author13f[:1]\n",
    "df13f['Vertical']=vertical13f[:1]\n",
    "df13f['Healines']=headline13f[:1]\n",
    "df13f['Description']=description13f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2988a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b550a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13g=[]\n",
    "author13g=[]\n",
    "vertical13g=[]\n",
    "headline13g=[]\n",
    "description13g=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author13g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical13g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "2640eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13g=pd.DataFrame({})\n",
    "df13g['Date']=date13g[:1]\n",
    "df13g['Author']=author13g[:1]\n",
    "df13g['Vertical']=vertical13g[:1]\n",
    "df13g['Healines']=headline13g[:1]\n",
    "df13g['Description']=description13g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4ca9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a1f5ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13h=[]\n",
    "author13h=[]\n",
    "vertical13h=[]\n",
    "headline13h=[]\n",
    "description13h=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author13h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|amritsar']\")\n",
    "for i in ve:\n",
    "    vertical13h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d0988cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13h=pd.DataFrame({})\n",
    "df13h['Date']=date13h[:1]\n",
    "df13h['Author']=author13h[:1]\n",
    "df13h['Vertical']=vertical13h[:1]\n",
    "df13h['Healines']=headline13h[:1]\n",
    "df13h['Description']=description13h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9713b4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "0b9fd83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date13i=[]\n",
    "author13i=[]\n",
    "vertical13i=[]\n",
    "headline13i=[]\n",
    "description13i=[]\n",
    "\n",
    "# scrapping details 13 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date13i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author13i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|events']\")\n",
    "for i in ve:\n",
    "    vertical13i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline13i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description13i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2d10c7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df13i=pd.DataFrame({})\n",
    "df13i['Date']=date13i[:1]\n",
    "df13i['Author']=author13i[:1]\n",
    "df13i['Vertical']=vertical13i[:1]\n",
    "df13i['Healines']=headline13i[:1]\n",
    "df13i['Description']=description13i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aedefa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cdff77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "6aae2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14=[]\n",
    "author14=[]\n",
    "vertical14=[]\n",
    "headline14=[]\n",
    "description14=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author14.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    vertical14.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f356c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14=pd.DataFrame({})\n",
    "df14['Date']=date14[:1]\n",
    "df14['Author']=author14[:1]\n",
    "df14['Vertical']=vertical14[:1]\n",
    "df14['Healines']=headline14[:1]\n",
    "df14['Description']=description14[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d50eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0edc6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14a=[]\n",
    "author14a=[]\n",
    "vertical14a=[]\n",
    "headline14a=[]\n",
    "description14a=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author14a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical14a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "2d33fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14a=pd.DataFrame({})\n",
    "df14a['Date']=date14a[:1]\n",
    "df14a['Author']=author14a[:1]\n",
    "df14a['Vertical']=vertical14a[:1]\n",
    "df14a['Healines']=headline14a[:1]\n",
    "df14a['Description']=description14a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460cb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "eba5a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14b=[]\n",
    "author14b=[]\n",
    "vertical14b=[]\n",
    "headline14b=[]\n",
    "description14b=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author14b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical14b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "d174520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14b=pd.DataFrame({})\n",
    "df14b['Date']=date14b[:1]\n",
    "df14b['Author']=author14b[:1]\n",
    "df14b['Vertical']=vertical14b[:1]\n",
    "df14b['Healines']=headline14b[:1]\n",
    "df14b['Description']=description14b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1a196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "5f6097d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14c=[]\n",
    "author14c=[]\n",
    "vertical14c=[]\n",
    "headline14c=[]\n",
    "description14c=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author14c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ahmedabad']\")\n",
    "for i in ve:\n",
    "    vertical14c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "694e8edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14c=pd.DataFrame({})\n",
    "df14c['Date']=date14c[:1]\n",
    "df14c['Author']=author14c[:1]\n",
    "df14c['Vertical']=vertical14c[:1]\n",
    "df14c['Healines']=headline14c[:1]\n",
    "df14c['Description']=description14c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6003c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "9b5c2bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14d=[]\n",
    "author14d=[]\n",
    "vertical14d=[]\n",
    "headline14d=[]\n",
    "description14d=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author14d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Cricket']\")\n",
    "for i in ve:\n",
    "    vertical14d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "895b5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14d=pd.DataFrame({})\n",
    "df14d['Date']=date14d[:1]\n",
    "df14d['Author']=author14d[:1]\n",
    "df14d['Vertical']=vertical14d[:1]\n",
    "df14d['Healines']=headline14d[:1]\n",
    "df14d['Description']=description14d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49a940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "8dbe8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14e=[]\n",
    "author14e=[]\n",
    "vertical14e=[]\n",
    "headline14e=[]\n",
    "description14e=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author14e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical14e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "6c667991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14e=pd.DataFrame({})\n",
    "df14e['Date']=date14e[:1]\n",
    "df14e['Author']=author14e[:1]\n",
    "df14e['Vertical']=vertical14e[:1]\n",
    "df14e['Healines']=headline14e[:1]\n",
    "df14e['Description']=description14e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432eb341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "771f8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14f=[]\n",
    "author14f=[]\n",
    "vertical14f=[]\n",
    "headline14f=[]\n",
    "description14f=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author14f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Shooting']\")\n",
    "for i in ve:\n",
    "    vertical14f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "f3f66a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14f=pd.DataFrame({})\n",
    "df14f['Date']=date14f[:1]\n",
    "df14f['Author']=author14f[:1]\n",
    "df14f['Vertical']=vertical14f[:1]\n",
    "df14f['Healines']=headline14f[:1]\n",
    "df14f['Description']=description14f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e52d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "5007bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14g=[]\n",
    "author14g=[]\n",
    "vertical14g=[]\n",
    "headline14g=[]\n",
    "description14g=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author14g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical14g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f631a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14g=pd.DataFrame({})\n",
    "df14g['Date']=date14g[:1]\n",
    "df14g['Author']=author14g[:1]\n",
    "df14g['Vertical']=vertical14g[:1]\n",
    "df14g['Healines']=headline14g[:1]\n",
    "df14g['Description']=description14g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55506e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6f013ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14h=[]\n",
    "author14h=[]\n",
    "vertical14h=[]\n",
    "headline14h=[]\n",
    "description14h=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author14h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical14h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "dd2aee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14h=pd.DataFrame({})\n",
    "df14h['Date']=date14h[:1]\n",
    "df14h['Author']=author14h[:1]\n",
    "df14h['Vertical']=vertical14h[:1]\n",
    "df14h['Healines']=headline14h[:1]\n",
    "df14h['Description']=description14h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f9995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6e005476",
   "metadata": {},
   "outputs": [],
   "source": [
    "date14i=[]\n",
    "author14i=[]\n",
    "vertical14i=[]\n",
    "headline14i=[]\n",
    "description14i=[]\n",
    "\n",
    "# scrapping details 14 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date14i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author14i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical14i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline14i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description14i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "190d5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14i=pd.DataFrame({})\n",
    "df14i['Date']=date14i[:1]\n",
    "df14i['Author']=author14i[:1]\n",
    "df14i['Vertical']=vertical14i[:1]\n",
    "df14i['Healines']=headline14i[:1]\n",
    "df14i['Description']=description14i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6090a594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf6421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6f8ab43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15=[]\n",
    "author15=[]\n",
    "vertical15=[]\n",
    "headline15=[]\n",
    "description15=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author15.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical15.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "7646ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15=pd.DataFrame({})\n",
    "df15['Date']=date15[:1]\n",
    "df15['Author']=author15[:1]\n",
    "df15['Vertical']=vertical15[:1]\n",
    "df15['Healines']=headline15[:1]\n",
    "df15['Description']=description15[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3a0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "3729f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15a=[]\n",
    "author15a=[]\n",
    "vertical15a=[]\n",
    "headline15a=[]\n",
    "description15a=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author15a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical15a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "3580deab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15a=pd.DataFrame({})\n",
    "df15a['Date']=date15a[:1]\n",
    "df15a['Author']=author15a[:1]\n",
    "df15a['Vertical']=vertical15a[:1]\n",
    "df15a['Healines']=headline15a[:1]\n",
    "df15a['Description']=description15a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755eb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "82430996",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15b=[]\n",
    "author15b=[]\n",
    "vertical15b=[]\n",
    "headline15b=[]\n",
    "description15b=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author15b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical15b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "1897f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15b=pd.DataFrame({})\n",
    "df15b['Date']=date15b[:1]\n",
    "df15b['Author']=author15b[:1]\n",
    "df15b['Vertical']=vertical15b[:1]\n",
    "df15b['Healines']=headline15b[:1]\n",
    "df15b['Description']=description15b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2940d758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "a7b43325",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15c=[]\n",
    "author15c=[]\n",
    "vertical15c=[]\n",
    "headline15c=[]\n",
    "description15c=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author15c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical15c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "a74c0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15c=pd.DataFrame({})\n",
    "df15c['Date']=date15c[:1]\n",
    "df15c['Author']=author15c[:1]\n",
    "df15c['Vertical']=vertical15c[:1]\n",
    "df15c['Healines']=headline15c[:1]\n",
    "df15c['Description']=description15c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5a2bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "d24878e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15d=[]\n",
    "author15d=[]\n",
    "vertical15d=[]\n",
    "headline15d=[]\n",
    "description15d=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author15d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ahmedabad']\")\n",
    "for i in ve:\n",
    "    vertical15d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "848dc3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15d=pd.DataFrame({})\n",
    "df15d['Date']=date15d[:1]\n",
    "df15d['Author']=author15d[:1]\n",
    "df15d['Vertical']=vertical15d[:1]\n",
    "df15d['Healines']=headline15d[:1]\n",
    "df15d['Description']=description15d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ca85f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "2308400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15e=[]\n",
    "author15e=[]\n",
    "vertical15e=[]\n",
    "headline15e=[]\n",
    "description15e=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author15e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical15e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "ef1d76ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15e=pd.DataFrame({})\n",
    "df15e['Date']=date15e[:1]\n",
    "df15e['Author']=author15e[:1]\n",
    "df15e['Vertical']=vertical15e[:1]\n",
    "df15e['Healines']=headline15e[:1]\n",
    "df15e['Description']=description15[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9210635d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "ae1e0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15f=[]\n",
    "author15f=[]\n",
    "vertical15f=[]\n",
    "headline15f=[]\n",
    "description15f=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author15f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|bhopal']\")\n",
    "for i in ve:\n",
    "    vertical15f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "1caeeabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15f=pd.DataFrame({})\n",
    "df15f['Date']=date15f[:1]\n",
    "df15f['Author']=author15f[:1]\n",
    "df15f['Vertical']=vertical15f[:1]\n",
    "df15f['Healines']=headline15f[:1]\n",
    "df15f['Description']=description15f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b5c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "ec2a850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15g=[]\n",
    "author15g=[]\n",
    "vertical15g=[]\n",
    "headline15g=[]\n",
    "description15g=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author15g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical15g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "13e629e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15g=pd.DataFrame({})\n",
    "df15g['Date']=date15g[:1]\n",
    "df15g['Author']=author15g[:1]\n",
    "df15g['Vertical']=vertical15g[:1]\n",
    "df15g['Healines']=headline15g[:1]\n",
    "df15g['Description']=description15g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586c19f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "8cfc95b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15h=[]\n",
    "author15h=[]\n",
    "vertical15h=[]\n",
    "headline15h=[]\n",
    "description15h=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author15h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical15h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "07fc4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15h=pd.DataFrame({})\n",
    "df15h['Date']=date15h[:1]\n",
    "df15h['Author']=author15h[:1]\n",
    "df15h['Vertical']=vertical15h[:1]\n",
    "df15h['Healines']=headline15h[:1]\n",
    "df15h['Description']=description15h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00da3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "be83651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date15i=[]\n",
    "author15i=[]\n",
    "vertical15i=[]\n",
    "headline15i=[]\n",
    "description15i=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date15i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author15i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|bareilly']\")\n",
    "for i in ve:\n",
    "    vertical15i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline15i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description15i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "51862dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df15i=pd.DataFrame({})\n",
    "df15i['Date']=date15i[:1]\n",
    "df15i['Author']=author15i[:1]\n",
    "df15i['Vertical']=vertical15i[:1]\n",
    "df15i['Healines']=headline15i[:1]\n",
    "df15i['Description']=description15i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b255896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864044e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "d613c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16=[]\n",
    "author16=[]\n",
    "vertical16=[]\n",
    "headline16=[]\n",
    "description16=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author16.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|world']\")\n",
    "for i in ve:\n",
    "    vertical16.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "a08d439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16=pd.DataFrame({})\n",
    "df16['Date']=date16[:1]\n",
    "df16['Author']=author16[:1]\n",
    "df16['Vertical']=vertical16[:1]\n",
    "df16['Healines']=headline16[:1]\n",
    "df16['Description']=description16[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e2222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "d5ff5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16a=[]\n",
    "author16a=[]\n",
    "vertical16a=[]\n",
    "headline16a=[]\n",
    "description16a=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author16a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|shimla']\")\n",
    "for i in ve:\n",
    "    vertical16a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "481778b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16a=pd.DataFrame({})\n",
    "df16a['Date']=date16a[:1]\n",
    "df16a['Author']=author16a[:1]\n",
    "df16a['Vertical']=vertical16a[:1]\n",
    "df16a['Healines']=headline16a[:1]\n",
    "df16a['Description']=description16a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df0aaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "1b006e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16b=[]\n",
    "author16b=[]\n",
    "vertical16b=[]\n",
    "headline16b=[]\n",
    "description16b=[]\n",
    "\n",
    "# scrapping details 15 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author16b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical16b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "5a2adc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16b=pd.DataFrame({})\n",
    "df16b['Date']=date16b[:1]\n",
    "df16b['Author']=author16b[:1]\n",
    "df16b['Vertical']=vertical16b[:1]\n",
    "df16b['Healines']=headline16b[:1]\n",
    "df16b['Description']=description16b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e93f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "b5f49776",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16c=[]\n",
    "author16c=[]\n",
    "vertical16c=[]\n",
    "headline16c=[]\n",
    "description16c=[]\n",
    "\n",
    "# scrapping details 16 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author16c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical16c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "50ca426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16c=pd.DataFrame({})\n",
    "df16c['Date']=date16c[:1]\n",
    "df16c['Author']=author16c[:1]\n",
    "df16c['Vertical']=vertical16c[:1]\n",
    "df16c['Healines']=headline16c[:1]\n",
    "df16c['Description']=description16c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16712e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "a82efd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16d=[]\n",
    "author16d=[]\n",
    "vertical16d=[]\n",
    "headline16d=[]\n",
    "description16d=[]\n",
    "\n",
    "# scrapping details 16 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author16d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical16d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "674ceebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16d=pd.DataFrame({})\n",
    "df16d['Date']=date16d[:1]\n",
    "df16d['Author']=author16d[:1]\n",
    "df16d['Vertical']=vertical16d[:1]\n",
    "df16d['Healines']=headline16d[:1]\n",
    "df16d['Description']=description16d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ebb43e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "206a616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16e=[]\n",
    "author16e=[]\n",
    "vertical16e=[]\n",
    "headline16e=[]\n",
    "description16e=[]\n",
    "\n",
    "# scrapping details 16 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author16e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical16e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "64ec61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16e=pd.DataFrame({})\n",
    "df16e['Date']=date16e[:1]\n",
    "df16e['Author']=author16e[:1]\n",
    "df16e['Vertical']=vertical16e[:1]\n",
    "df16e['Healines']=headline16e[:1]\n",
    "df16e['Description']=description16e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd5c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "5433ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16f=[]\n",
    "author16f=[]\n",
    "vertical16f=[]\n",
    "headline16f=[]\n",
    "description16f=[]\n",
    "\n",
    "# scrapping details 16 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author16f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|citizen reporter']\")\n",
    "for i in ve:\n",
    "    vertical16f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "31804248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16f=pd.DataFrame({})\n",
    "df16f['Date']=date16f[:1]\n",
    "df16f['Author']=author16f[:1]\n",
    "df16f['Vertical']=vertical16f[:1]\n",
    "df16f['Healines']=headline16f[:1]\n",
    "df16f['Description']=description16f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92757a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "9f347dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16g=[]\n",
    "author16g=[]\n",
    "vertical16g=[]\n",
    "headline16g=[]\n",
    "description16g=[]\n",
    "\n",
    "# scrapping details 16 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author16g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|citizen reporter']\")\n",
    "for i in ve:\n",
    "    vertical16g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "ff538bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16g=pd.DataFrame({})\n",
    "df16g['Date']=date16g[:1]\n",
    "df16g['Author']=author16g[:1]\n",
    "df16g['Vertical']=vertical16g[:1]\n",
    "df16g['Healines']=headline16g[:1]\n",
    "df16g['Description']=description16g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580d9227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "a4dd31f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16h=[]\n",
    "author16h=[]\n",
    "vertical16h=[]\n",
    "headline16h=[]\n",
    "description16h=[]\n",
    "\n",
    "# scrapping details 16 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author16h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical16h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "f871194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16h=pd.DataFrame({})\n",
    "df16h['Date']=date16h[:1]\n",
    "df16h['Author']=author16h[:1]\n",
    "df16h['Vertical']=vertical16h[:1]\n",
    "df16h['Healines']=headline16h[:1]\n",
    "df16h['Description']=description16h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407831ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "ab81dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "date16i=[]\n",
    "author16i=[]\n",
    "vertical16i=[]\n",
    "headline16i=[]\n",
    "description16i=[]\n",
    "\n",
    "# scrapping details 16 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date16i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author16i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|shillong']\")\n",
    "for i in ve:\n",
    "    vertical16i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline16i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description16i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "9e52907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df16i=pd.DataFrame({})\n",
    "df16i['Date']=date16i[:1]\n",
    "df16i['Author']=author16i[:1]\n",
    "df16i['Vertical']=vertical16i[:1]\n",
    "df16i['Healines']=headline16i[:1]\n",
    "df16i['Description']=description16i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8744ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d237c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "1ae694fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17=[]\n",
    "author17=[]\n",
    "vertical17=[]\n",
    "headline17=[]\n",
    "description17=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author17.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical17.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "a6aa7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17=pd.DataFrame({})\n",
    "df17['Date']=date17[:1]\n",
    "df17['Author']=author17[:1]\n",
    "df17['Vertical']=vertical17[:1]\n",
    "df17['Healines']=headline17[:1]\n",
    "df17['Description']=description17[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87eb25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "37285a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17a=[]\n",
    "author17a=[]\n",
    "vertical17a=[]\n",
    "headline17a=[]\n",
    "description17a=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author17a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|madurai']\")\n",
    "for i in ve:\n",
    "    vertical17a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "43c7faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17a=pd.DataFrame({})\n",
    "df17a['Date']=date17a[:1]\n",
    "df17a['Author']=author17a[:1]\n",
    "df17a['Vertical']=vertical17a[:1]\n",
    "df17a['Healines']=headline17a[:1]\n",
    "df17a['Description']=description17a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcca1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "72270b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17b=[]\n",
    "author17b=[]\n",
    "vertical17b=[]\n",
    "headline17b=[]\n",
    "description17b=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author17b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|raipur']\")\n",
    "for i in ve:\n",
    "    vertical17b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "f81c39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17b=pd.DataFrame({})\n",
    "df17b['Date']=date17b[:1]\n",
    "df17b['Author']=author17b[:1]\n",
    "df17b['Vertical']=vertical17b[:1]\n",
    "df17b['Healines']=headline17b[:1]\n",
    "df17b['Description']=description17b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77005903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "e9b26ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17c=[]\n",
    "author17c=[]\n",
    "vertical17c=[]\n",
    "headline17c=[]\n",
    "description17c=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author17c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical17c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "894f6389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17c=pd.DataFrame({})\n",
    "df17c['Date']=date17c[:1]\n",
    "df17c['Author']=author17c[:1]\n",
    "df17c['Vertical']=vertical17c[:1]\n",
    "df17c['Healines']=headline17c[:1]\n",
    "df17c['Description']=description17c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbbc362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "f4edb2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17d=[]\n",
    "author17d=[]\n",
    "vertical17d=[]\n",
    "headline17d=[]\n",
    "description17d=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author17d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|amritsar']\")\n",
    "for i in ve:\n",
    "    vertical17d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "0227be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17d=pd.DataFrame({})\n",
    "df17d['Date']=date17d[:1]\n",
    "df17d['Author']=author17d[:1]\n",
    "df17d['Vertical']=vertical17d[:1]\n",
    "df17d['Healines']=headline17d[:1]\n",
    "df17d['Description']=description17d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e42e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "10556852",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17e=[]\n",
    "author17e=[]\n",
    "vertical17e=[]\n",
    "headline17e=[]\n",
    "description17e=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author17e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical17e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "1eaae762",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17e=pd.DataFrame({})\n",
    "df17e['Date']=date17e[:1]\n",
    "df17e['Author']=author17e[:1]\n",
    "df17e['Vertical']=vertical17e[:1]\n",
    "df17e['Healines']=headline17e[:1]\n",
    "df17e['Description']=description17e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e624c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "a8bb0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17f=[]\n",
    "author17f=[]\n",
    "vertical17f=[]\n",
    "headline17f=[]\n",
    "description17f=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author17f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical17f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "7d252738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17f=pd.DataFrame({})\n",
    "df17f['Date']=date17f[:1]\n",
    "df17f['Author']=author17f[:1]\n",
    "df17f['Vertical']=vertical17f[:1]\n",
    "df17f['Healines']=headline17f[:1]\n",
    "df17f['Description']=description17f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9294746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "6d4750c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17g=[]\n",
    "author17g=[]\n",
    "vertical17g=[]\n",
    "headline17g=[]\n",
    "description17g=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author17g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|indore']\")\n",
    "for i in ve:\n",
    "    vertical17g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "274f3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17g=pd.DataFrame({})\n",
    "df17g['Date']=date17g[:1]\n",
    "df17g['Author']=author17g[:1]\n",
    "df17g['Vertical']=vertical17g[:1]\n",
    "df17g['Healines']=headline17g[:1]\n",
    "df17g['Description']=description17g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863193eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "6d2a5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17h=[]\n",
    "author17h=[]\n",
    "vertical17h=[]\n",
    "headline17h=[]\n",
    "description17h=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author17h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical17h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "9a850aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17h=pd.DataFrame({})\n",
    "df17h['Date']=date17h[:1]\n",
    "df17h['Author']=author17h[:1]\n",
    "df17h['Vertical']=vertical17h[:1]\n",
    "df17h['Healines']=headline17h[:1]\n",
    "df17h['Description']=description17h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3beb177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "335866e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date17i=[]\n",
    "author17i=[]\n",
    "vertical17i=[]\n",
    "headline17i=[]\n",
    "description17i=[]\n",
    "\n",
    "# scrapping details 17 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date17i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author17i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical17i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline17i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description17i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "f56f9bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df17i=pd.DataFrame({})\n",
    "df17i['Date']=date17i[:1]\n",
    "df17i['Author']=author17i[:1]\n",
    "df17i['Vertical']=vertical17i[:1]\n",
    "df17i['Healines']=headline17i[:1]\n",
    "df17i['Description']=description17i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a6868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b434579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "7656fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18=[]\n",
    "author18=[]\n",
    "vertical18=[]\n",
    "headline18=[]\n",
    "description18=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author18.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical18.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "4d64ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18=pd.DataFrame({})\n",
    "df18['Date']=date18[:1]\n",
    "df18['Author']=author18[:1]\n",
    "df18['Vertical']=vertical18[:1]\n",
    "df18['Healines']=headline18[:1]\n",
    "df18['Description']=description18[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42ca51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "34fc1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18a=[]\n",
    "author18a=[]\n",
    "vertical18a=[]\n",
    "headline18a=[]\n",
    "description18a=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author18a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical18a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "37cb0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18a=pd.DataFrame({})\n",
    "df18a['Date']=date18a[:1]\n",
    "df18a['Author']=author18a[:1]\n",
    "df18a['Vertical']=vertical18a[:1]\n",
    "df18a['Healines']=headline18a[:1]\n",
    "df18a['Description']=description18a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008866b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "c3fc1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18b=[]\n",
    "author18b=[]\n",
    "vertical18b=[]\n",
    "headline18b=[]\n",
    "description18b=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author18b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ahmedabad']\")\n",
    "for i in ve:\n",
    "    vertical18b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "d1ca2373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18b=pd.DataFrame({})\n",
    "df18b['Date']=date18b[:1]\n",
    "df18b['Author']=author18b[:1]\n",
    "df18b['Vertical']=vertical18b[:1]\n",
    "df18b['Healines']=headline18b[:1]\n",
    "df18b['Description']=description18b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3551021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "e7f3bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18c=[]\n",
    "author18c=[]\n",
    "vertical18c=[]\n",
    "headline18c=[]\n",
    "description18c=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author18c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical18c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "d536ec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18c=pd.DataFrame({})\n",
    "df18c['Date']=date18c[:1]\n",
    "df18c['Author']=author18c[:1]\n",
    "df18c['Vertical']=vertical18c[:1]\n",
    "df18c['Healines']=headline18c[:1]\n",
    "df18c['Description']=description18c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d4219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "0e6f40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18d=[]\n",
    "author18d=[]\n",
    "vertical18d=[]\n",
    "headline18d=[]\n",
    "description18d=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author18d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical18d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "e17dde80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18d=pd.DataFrame({})\n",
    "df18d['Date']=date18d[:1]\n",
    "df18d['Author']=author18d[:1]\n",
    "df18d['Vertical']=vertical18d[:1]\n",
    "df18d['Healines']=headline18d[:1]\n",
    "df18d['Description']=description18d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865e1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "b04e8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18e=[]\n",
    "author18e=[]\n",
    "vertical18e=[]\n",
    "headline18e=[]\n",
    "description18e=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author18e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical18e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "2100a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18e=pd.DataFrame({})\n",
    "df18e['Date']=date18e[:1]\n",
    "df18e['Author']=author18e[:1]\n",
    "df18e['Vertical']=vertical18e[:1]\n",
    "df18e['Healines']=headline18e[:1]\n",
    "df18e['Description']=description18e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edb6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "aa72a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18f=[]\n",
    "author18f=[]\n",
    "vertical18f=[]\n",
    "headline18f=[]\n",
    "description18f=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author18f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical18f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "21fdf084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18f=pd.DataFrame({})\n",
    "df18f['Date']=date18f[:1]\n",
    "df18f['Author']=author18f[:1]\n",
    "df18f['Vertical']=vertical18f[:1]\n",
    "df18f['Healines']=headline18f[:1]\n",
    "df18f['Description']=description18f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874b242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "acabcc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18g=[]\n",
    "author18g=[]\n",
    "vertical18g=[]\n",
    "headline18g=[]\n",
    "description18g=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author18g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical18g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "5848ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18g=pd.DataFrame({})\n",
    "df18g['Date']=date18g[:1]\n",
    "df18g['Author']=author18g[:1]\n",
    "df18g['Vertical']=vertical18g[:1]\n",
    "df18g['Healines']=headline18g[:1]\n",
    "df18g['Description']=description18g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd04e40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "e19066bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18h=[]\n",
    "author18h=[]\n",
    "vertical18h=[]\n",
    "headline18h=[]\n",
    "description18h=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author18h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical18h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "9ec2dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18h=pd.DataFrame({})\n",
    "df18h['Date']=date18h[:1]\n",
    "df18h['Author']=author18h[:1]\n",
    "df18h['Vertical']=vertical18h[:1]\n",
    "df18h['Healines']=headline18h[:1]\n",
    "df18h['Description']=description18h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c9694c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "76a73640",
   "metadata": {},
   "outputs": [],
   "source": [
    "date18i=[]\n",
    "author18i=[]\n",
    "vertical18i=[]\n",
    "headline18i=[]\n",
    "description18i=[]\n",
    "\n",
    "# scrapping details 18 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date18i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author18i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical18i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline18i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description18i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "f0bb7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18i=pd.DataFrame({})\n",
    "df18i['Date']=date18i[:1]\n",
    "df18i['Author']=author18i[:1]\n",
    "df18i['Vertical']=vertical18i[:1]\n",
    "df18i['Healines']=headline18i[:1]\n",
    "df18i['Description']=description18i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502c79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dddba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "18cc24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19=[]\n",
    "author19=[]\n",
    "vertical19=[]\n",
    "headline19=[]\n",
    "description19=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author19.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical19.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "c50d852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19=pd.DataFrame({})\n",
    "df19['Date']=date19[:1]\n",
    "df19['Author']=author19[:1]\n",
    "df19['Vertical']=vertical19[:1]\n",
    "df19['Healines']=headline19[:1]\n",
    "df19['Description']=description19[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156095bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "0932305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19a=[]\n",
    "author19a=[]\n",
    "vertical19a=[]\n",
    "headline19a=[]\n",
    "description19a=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author19a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical19a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "e59ac4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19a=pd.DataFrame({})\n",
    "df19a['Date']=date19a[:1]\n",
    "df19a['Author']=author19a[:1]\n",
    "df19a['Vertical']=vertical19a[:1]\n",
    "df19a['Healines']=headline19a[:1]\n",
    "df19a['Description']=description19a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d037a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "66a59820",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19b=[]\n",
    "author19b=[]\n",
    "vertical19b=[]\n",
    "headline19b=[]\n",
    "description19b=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author19b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical19b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "bfbb14a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19b=pd.DataFrame({})\n",
    "df19b['Date']=date19b[:1]\n",
    "df19b['Author']=author19b[:1]\n",
    "df19b['Vertical']=vertical19b[:1]\n",
    "df19b['Healines']=headline19b[:1]\n",
    "df19b['Description']=description19b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271ceca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "33fb4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19c=[]\n",
    "author19c=[]\n",
    "vertical19c=[]\n",
    "headline19c=[]\n",
    "description19c=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author19c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical19c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "cd4f567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19c=pd.DataFrame({})\n",
    "df19c['Date']=date19c[:1]\n",
    "df19c['Author']=author19c[:1]\n",
    "df19c['Vertical']=vertical19c[:1]\n",
    "df19c['Healines']=headline19c[:1]\n",
    "df19c['Description']=description19c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce17830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "f86030b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19d=[]\n",
    "author19d=[]\n",
    "vertical19d=[]\n",
    "headline19d=[]\n",
    "description19d=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author19d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical19d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "a945930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19d=pd.DataFrame({})\n",
    "df19d['Date']=date19d[:1]\n",
    "df19d['Author']=author19d[:1]\n",
    "df19d['Vertical']=vertical19d[:1]\n",
    "df19d['Healines']=headline19d[:1]\n",
    "df19d['Description']=description19d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b100e497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "def64243",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19e=[]\n",
    "author19e=[]\n",
    "vertical19e=[]\n",
    "headline19e=[]\n",
    "description19e=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author19e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical19e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "4b446b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19e=pd.DataFrame({})\n",
    "df19e['Date']=date19e[:1]\n",
    "df19e['Author']=author19e[:1]\n",
    "df19e['Vertical']=vertical19e[:1]\n",
    "df19e['Healines']=headline19e[:1]\n",
    "df19e['Description']=description19e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56a484c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "cc5ba434",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19f=[]\n",
    "author19f=[]\n",
    "vertical19f=[]\n",
    "headline19f=[]\n",
    "description19f=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author19f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical19f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "a1d470d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19f=pd.DataFrame({})\n",
    "df19f['Date']=date19f[:1]\n",
    "df19f['Author']=author19f[:1]\n",
    "df19f['Vertical']=vertical19f[:1]\n",
    "df19f['Healines']=headline19f[:1]\n",
    "df19f['Description']=description19f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d097b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "a9b199f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19g=[]\n",
    "author19g=[]\n",
    "vertical19g=[]\n",
    "headline19g=[]\n",
    "description19g=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author19g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical19g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "605369f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19g=pd.DataFrame({})\n",
    "df19g['Date']=date19g[:1]\n",
    "df19g['Author']=author19g[:1]\n",
    "df19g['Vertical']=vertical19g[:1]\n",
    "df19g['Healines']=headline19g[:1]\n",
    "df19g['Description']=description19g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04a015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "de1b5668",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19h=[]\n",
    "author19h=[]\n",
    "vertical19h=[]\n",
    "headline19h=[]\n",
    "description19h=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author19h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|events']\")\n",
    "for i in ve:\n",
    "    vertical19h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "489f041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19h=pd.DataFrame({})\n",
    "df19h['Date']=date19h[:1]\n",
    "df19h['Author']=author19h[:1]\n",
    "df19h['Vertical']=vertical19h[:1]\n",
    "df19h['Healines']=headline19h[:1]\n",
    "df19h['Description']=description19h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a59185b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "0e73b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "date19i=[]\n",
    "author19i=[]\n",
    "vertical19i=[]\n",
    "headline19i=[]\n",
    "description19i=[]\n",
    "\n",
    "# scrapping details 19 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date19i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author19i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical19i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline19i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description19i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "30a088a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df19i=pd.DataFrame({})\n",
    "df19i['Date']=date19i[:1]\n",
    "df19i['Author']=author19i[:1]\n",
    "df19i['Vertical']=vertical19i[:1]\n",
    "df19i['Healines']=headline19i[:1]\n",
    "df19i['Description']=description19i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a42fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc721c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "61cc0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20=[]\n",
    "author20=[]\n",
    "vertical20=[]\n",
    "headline20=[]\n",
    "description20=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author20.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical20.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "b658d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20=pd.DataFrame({})\n",
    "df20['Date']=date20[:1]\n",
    "df20['Author']=author20[:1]\n",
    "df20['Vertical']=vertical20[:1]\n",
    "df20['Healines']=headline20[:1]\n",
    "df20['Description']=description20[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ab081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "d095f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20a=[]\n",
    "author20a=[]\n",
    "vertical20a=[]\n",
    "headline20a=[]\n",
    "description20a=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author20a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical20a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "82dcfd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20a=pd.DataFrame({})\n",
    "df20a['Date']=date20a[:1]\n",
    "df20a['Author']=author20a[:1]\n",
    "df20a['Vertical']=vertical20a[:1]\n",
    "df20a['Healines']=headline20a[:1]\n",
    "df20a['Description']=description20a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d508b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "5fe3e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20b=[]\n",
    "author20b=[]\n",
    "vertical20b=[]\n",
    "headline20b=[]\n",
    "description20b=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author20b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical20b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "152264f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20b=pd.DataFrame({})\n",
    "df20b['Date']=date20b[:1]\n",
    "df20b['Author']=author20b[:1]\n",
    "df20b['Vertical']=vertical20b[:1]\n",
    "df20b['Healines']=headline20b[:1]\n",
    "df20b['Description']=description20b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207907e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "8770bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20c=[]\n",
    "author20c=[]\n",
    "vertical20c=[]\n",
    "headline20c=[]\n",
    "description20c=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author20c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical20c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "853a1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20c=pd.DataFrame({})\n",
    "df20c['Date']=date20c[:1]\n",
    "df20c['Author']=author20c[:1]\n",
    "df20c['Vertical']=vertical20c[:1]\n",
    "df20c['Healines']=headline20c[:1]\n",
    "df20c['Description']=description20c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168c347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "6e6ae023",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20d=[]\n",
    "author20d=[]\n",
    "vertical20d=[]\n",
    "headline20d=[]\n",
    "description20d=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author20d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|indore']\")\n",
    "for i in ve:\n",
    "    vertical20d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "9ab78b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20d=pd.DataFrame({})\n",
    "df20d['Date']=date20d[:1]\n",
    "df20d['Author']=author20d[:1]\n",
    "df20d['Vertical']=vertical20d[:1]\n",
    "df20d['Healines']=headline20d[:1]\n",
    "df20d['Description']=description20d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d46a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "9bfc4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20e=[]\n",
    "author20e=[]\n",
    "vertical20e=[]\n",
    "headline20e=[]\n",
    "description20e=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author20e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical20e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "1ff7c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20e=pd.DataFrame({})\n",
    "df20e['Date']=date20e[:1]\n",
    "df20e['Author']=author20e[:1]\n",
    "df20e['Vertical']=vertical20e[:1]\n",
    "df20e['Healines']=headline20e[:1]\n",
    "df20e['Description']=description20e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c0bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "744d78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20f=[]\n",
    "author20f=[]\n",
    "vertical20f=[]\n",
    "headline20f=[]\n",
    "description20f=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author20f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical20f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "9c29b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20f=pd.DataFrame({})\n",
    "df20f['Date']=date20f[:1]\n",
    "df20f['Author']=author20f[:1]\n",
    "df20f['Vertical']=vertical20f[:1]\n",
    "df20f['Healines']=headline20f[:1]\n",
    "df20f['Description']=description20f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369da233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "fed42045",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20g=[]\n",
    "author20g=[]\n",
    "vertical20g=[]\n",
    "headline20g=[]\n",
    "description20g=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author20g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical20g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "e46d131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20g=pd.DataFrame({})\n",
    "df20g['Date']=date20g[:1]\n",
    "df20g['Author']=author20g[:1]\n",
    "df20g['Vertical']=vertical20g[:1]\n",
    "df20g['Healines']=headline20g[:1]\n",
    "df20g['Description']=description20g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f258b5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "a920f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20h=[]\n",
    "author20h=[]\n",
    "vertical20h=[]\n",
    "headline20h=[]\n",
    "description20h=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author20h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|mangaluru']\")\n",
    "for i in ve:\n",
    "    vertical20h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "d25b53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20h=pd.DataFrame({})\n",
    "df20h['Date']=date20h[:1]\n",
    "df20h['Author']=author20h[:1]\n",
    "df20h['Vertical']=vertical20h[:1]\n",
    "df20h['Healines']=headline20h[:1]\n",
    "df20h['Description']=description20h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2efa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "464eb705",
   "metadata": {},
   "outputs": [],
   "source": [
    "date20i=[]\n",
    "author20i=[]\n",
    "vertical20i=[]\n",
    "headline20i=[]\n",
    "description20i=[]\n",
    "\n",
    "# scrapping details 20 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date20i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author20i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|events']\")\n",
    "for i in ve:\n",
    "    vertical20i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline20i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description20i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "0c664abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df20i=pd.DataFrame({})\n",
    "df20i['Date']=date20i[:1]\n",
    "df20i['Author']=author20i[:1]\n",
    "df20i['Vertical']=vertical20i[:1]\n",
    "df20i['Healines']=headline20i[:1]\n",
    "df20i['Description']=description20i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ee8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fcb8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "dc891639",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21=[]\n",
    "author21=[]\n",
    "vertical21=[]\n",
    "headline21=[]\n",
    "description21=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author21.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|kanpur']\")\n",
    "for i in ve:\n",
    "    vertical21.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "8560941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21=pd.DataFrame({})\n",
    "df21['Date']=date21[:1]\n",
    "df21['Author']=author21[:1]\n",
    "df21['Vertical']=vertical21[:1]\n",
    "df21['Healines']=headline21[:1]\n",
    "df21['Description']=description21[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04fca9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "9ecc8bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21a=[]\n",
    "author21a=[]\n",
    "vertical21a=[]\n",
    "headline21a=[]\n",
    "description21a=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author21a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical21a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "42feabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21a=pd.DataFrame({})\n",
    "df21a['Date']=date21a[:1]\n",
    "df21a['Author']=author21a[:1]\n",
    "df21a['Vertical']=vertical21a[:1]\n",
    "df21a['Healines']=headline21a[:1]\n",
    "df21a['Description']=description21a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8872d9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "4f21ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21b=[]\n",
    "author21b=[]\n",
    "vertical21b=[]\n",
    "headline21b=[]\n",
    "description21b=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author21b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical21b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "e1813696",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21b=pd.DataFrame({})\n",
    "df21b['Date']=date21b[:1]\n",
    "df21b['Author']=author21b[:1]\n",
    "df21b['Vertical']=vertical21b[:1]\n",
    "df21b['Healines']=headline21b[:1]\n",
    "df21b['Description']=description21b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367ce9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "d5f5d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21c=[]\n",
    "author21c=[]\n",
    "vertical21c=[]\n",
    "headline21c=[]\n",
    "description21c=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author21c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|aurangabad']\")\n",
    "for i in ve:\n",
    "    vertical21c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "b22ca3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21c=pd.DataFrame({})\n",
    "df21c['Date']=date21c[:1]\n",
    "df21c['Author']=author21c[:1]\n",
    "df21c['Vertical']=vertical21c[:1]\n",
    "df21c['Healines']=headline21c[:1]\n",
    "df21c['Description']=description21c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da8113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "aec35dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21d=[]\n",
    "author21d=[]\n",
    "vertical21d=[]\n",
    "headline21d=[]\n",
    "description21d=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author21d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|kohima']\")\n",
    "for i in ve:\n",
    "    vertical21d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "51341168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21d=pd.DataFrame({})\n",
    "df21d['Date']=date21d[:1]\n",
    "df21d['Author']=author21d[:1]\n",
    "df21d['Vertical']=vertical21d[:1]\n",
    "df21d['Healines']=headline21d[:1]\n",
    "df21d['Description']=description21d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5dd18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "0f84c8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21e=[]\n",
    "author21e=[]\n",
    "vertical21e=[]\n",
    "headline21e=[]\n",
    "description21e=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author21e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical21e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "bbe1388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21e=pd.DataFrame({})\n",
    "df21e['Date']=date21e[:1]\n",
    "df21e['Author']=author21e[:1]\n",
    "df21e['Vertical']=vertical21e[:1]\n",
    "df21e['Healines']=headline21e[:1]\n",
    "df21e['Description']=description21e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b37664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "de926f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21f=[]\n",
    "author21f=[]\n",
    "vertical21f=[]\n",
    "headline21f=[]\n",
    "description21f=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author21f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ahmedabad']\")\n",
    "for i in ve:\n",
    "    vertical21f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "50deb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21f=pd.DataFrame({})\n",
    "df21f['Date']=date21f[:1]\n",
    "df21f['Author']=author21f[:1]\n",
    "df21f['Vertical']=vertical21f[:1]\n",
    "df21f['Healines']=headline21f[:1]\n",
    "df21f['Description']=description21f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91d06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "36832f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21g=[]\n",
    "author21g=[]\n",
    "vertical21g=[]\n",
    "headline21g=[]\n",
    "description21g=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author21g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|kanpur']\")\n",
    "for i in ve:\n",
    "    vertical21g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "d19f8cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21g=pd.DataFrame({})\n",
    "df21g['Date']=date21g[:1]\n",
    "df21g['Author']=author21g[:1]\n",
    "df21g['Vertical']=vertical21g[:1]\n",
    "df21g['Healines']=headline21g[:1]\n",
    "df21g['Description']=description21g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd3526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "dd551c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21h=[]\n",
    "author21h=[]\n",
    "vertical21h=[]\n",
    "headline21h=[]\n",
    "description21h=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author21h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|ahmedabad']\")\n",
    "for i in ve:\n",
    "    vertical21h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "79cbbf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21h=pd.DataFrame({})\n",
    "df21h['Date']=date21h[:1]\n",
    "df21h['Author']=author21h[:1]\n",
    "df21h['Vertical']=vertical21h[:1]\n",
    "df21h['Healines']=headline21h[:1]\n",
    "df21h['Description']=description21h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271d888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "6934f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date21i=[]\n",
    "author21i=[]\n",
    "vertical21i=[]\n",
    "headline21i=[]\n",
    "description21i=[]\n",
    "\n",
    "# scrapping details 21 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date21i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author21i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|rajkot']\")\n",
    "for i in ve:\n",
    "    vertical21i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline21i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description21i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "3469cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df21i=pd.DataFrame({})\n",
    "df21i['Date']=date21i[:1]\n",
    "df21i['Author']=author21i[:1]\n",
    "df21i['Vertical']=vertical21i[:1]\n",
    "df21i['Healines']=headline21i[:1]\n",
    "df21i['Description']=description21i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7104de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150d938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "00d06494",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22=[]\n",
    "author22=[]\n",
    "vertical22=[]\n",
    "headline22=[]\n",
    "description22=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author22.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical22.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "4f86e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22=pd.DataFrame({})\n",
    "df22['Date']=date22[:1]\n",
    "df22['Author']=author22[:1]\n",
    "df22['Vertical']=vertical22[:1]\n",
    "df22['Healines']=headline22[:1]\n",
    "df22['Description']=description22[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf2bca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "2a847c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22a=[]\n",
    "author22a=[]\n",
    "vertical22a=[]\n",
    "headline22a=[]\n",
    "description22a=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author22a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|meerut']\")\n",
    "for i in ve:\n",
    "    vertical22a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "86e6e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22a=pd.DataFrame({})\n",
    "df22a['Date']=date22a[:1]\n",
    "df22a['Author']=author22a[:1]\n",
    "df22a['Vertical']=vertical22a[:1]\n",
    "df22a['Healines']=headline22a[:1]\n",
    "df22a['Description']=description22a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6b40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "64b8c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22b=[]\n",
    "author22b=[]\n",
    "vertical22b=[]\n",
    "headline22b=[]\n",
    "description22b=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author22b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical22b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "f6b1e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22b=pd.DataFrame({})\n",
    "df22b['Date']=date22b[:1]\n",
    "df22b['Author']=author22b[:1]\n",
    "df22b['Vertical']=vertical22b[:1]\n",
    "df22b['Healines']=headline22b[:1]\n",
    "df22b['Description']=description22b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d21cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "94f2755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22c=[]\n",
    "author22c=[]\n",
    "vertical22c=[]\n",
    "headline22c=[]\n",
    "description22c=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author22c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical22c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "2b9e0a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22c=pd.DataFrame({})\n",
    "df22c['Date']=date22c[:1]\n",
    "df22['Author']=author22c[:1]\n",
    "df22c['Vertical']=vertical22c[:1]\n",
    "df22c['Healines']=headline22c[:1]\n",
    "df22c['Description']=description22c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2ace0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "97d87de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22d=[]\n",
    "author22d=[]\n",
    "vertical22d=[]\n",
    "headline22d=[]\n",
    "description22d=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author22d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical22d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "2172bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22d=pd.DataFrame({})\n",
    "df22d['Date']=date22d[:1]\n",
    "df22d['Author']=author22d[:1]\n",
    "df22d['Vertical']=vertical22d[:1]\n",
    "df22d['Healines']=headline22d[:1]\n",
    "df22d['Description']=description22d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe47cb34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "eeed31b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22e=[]\n",
    "author22e=[]\n",
    "vertical22e=[]\n",
    "headline22e=[]\n",
    "description22e=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author22e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical22e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "25f54ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22e=pd.DataFrame({})\n",
    "df22e['Date']=date22e[:1]\n",
    "df22e['Author']=author22e[:1]\n",
    "df22e['Vertical']=vertical22e[:1]\n",
    "df22e['Healines']=headline22e[:1]\n",
    "df22e['Description']=description22e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6105d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "9c01ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22f=[]\n",
    "author22f=[]\n",
    "vertical22f=[]\n",
    "headline22f=[]\n",
    "description22f=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author22f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical22f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "45ac19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22f=pd.DataFrame({})\n",
    "df22f['Date']=date22f[:1]\n",
    "df22f['Author']=author22f[:1]\n",
    "df22f['Vertical']=vertical22f[:1]\n",
    "df22f['Healines']=headline22f[:1]\n",
    "df22f['Description']=description22f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd30cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "007cb1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22g=[]\n",
    "author22g=[]\n",
    "vertical22g=[]\n",
    "headline22g=[]\n",
    "description22g=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author22g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|thane']\")\n",
    "for i in ve:\n",
    "    vertical22g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "ffd391a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22g=pd.DataFrame({})\n",
    "df22g['Date']=date22g[:1]\n",
    "df22g['Author']=author22g[:1]\n",
    "df22g['Vertical']=vertical22g[:1]\n",
    "df22g['Healines']=headline22g[:1]\n",
    "df22g['Description']=description22g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af210a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "1cce548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22h=[]\n",
    "author22h=[]\n",
    "vertical22h=[]\n",
    "headline22h=[]\n",
    "description22h=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author22h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical22h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "13325e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22h=pd.DataFrame({})\n",
    "df22h['Date']=date22h[:1]\n",
    "df22h['Author']=author22h[:1]\n",
    "df22h['Vertical']=vertical22h[:1]\n",
    "df22h['Healines']=headline22h[:1]\n",
    "df22h['Description']=description22h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f8387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "9c0592f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date22i=[]\n",
    "author22i=[]\n",
    "vertical22i=[]\n",
    "headline22i=[]\n",
    "description22i=[]\n",
    "\n",
    "# scrapping details 22 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date22i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author22i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical22i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline22i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description22i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "126ad34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df22i=pd.DataFrame({})\n",
    "df22i['Date']=date22i[:1]\n",
    "df22i['Author']=author22i[:1]\n",
    "df22i['Vertical']=vertical22i[:1]\n",
    "df22i['Healines']=headline22i[:1]\n",
    "df22i['Description']=description22i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f5e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206dc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "69aecf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23=[]\n",
    "author23=[]\n",
    "vertical23=[]\n",
    "headline23=[]\n",
    "description23=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author23.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    vertical23.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "e37afef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23=pd.DataFrame({})\n",
    "df23['Date']=date23[:1]\n",
    "df23['Author']=author23[:1]\n",
    "df23['Vertical']=vertical23[:1]\n",
    "df23['Healines']=headline23[:1]\n",
    "df23['Description']=description23[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f1ee82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "2d382f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23a=[]\n",
    "author23a=[]\n",
    "vertical23a=[]\n",
    "headline23a=[]\n",
    "description23a=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author23a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical23a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "6202e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23a=pd.DataFrame({})\n",
    "df23a['Date']=date23a[:1]\n",
    "df23a['Author']=author23a[:1]\n",
    "df23a['Vertical']=vertical23a[:1]\n",
    "df23a['Healines']=headline23a[:1]\n",
    "df23a['Description']=description23a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f05c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "8c592f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23b=[]\n",
    "author23b=[]\n",
    "vertical23b=[]\n",
    "headline23b=[]\n",
    "description23b=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author23b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical23b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "387c846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23b=pd.DataFrame({})\n",
    "df23b['Date']=date23b[:1]\n",
    "df23b['Author']=author23b[:1]\n",
    "df23b['Vertical']=vertical23b[:1]\n",
    "df23b['Healines']=headline23b[:1]\n",
    "df23b['Description']=description23b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd2b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "f28d2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23c=[]\n",
    "author23c=[]\n",
    "vertical23c=[]\n",
    "headline23c=[]\n",
    "description23c=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author23c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical23c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "9f8c16f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23c=pd.DataFrame({})\n",
    "df23c['Date']=date23c[:1]\n",
    "df23c['Author']=author23c[:1]\n",
    "df23c['Vertical']=vertical23c[:1]\n",
    "df23c['Healines']=headline23c[:1]\n",
    "df23c['Description']=description23c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96fc8bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "79ac1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23d=[]\n",
    "author23d=[]\n",
    "vertical23d=[]\n",
    "headline23d=[]\n",
    "description23d=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author23d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical23d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "31ce71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23d=pd.DataFrame({})\n",
    "df23d['Date']=date23d[:1]\n",
    "df23d['Author']=author23d[:1]\n",
    "df23d['Vertical']=vertical23d[:1]\n",
    "df23d['Healines']=headline23d[:1]\n",
    "df23d['Description']=description23d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245e857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "2f9ff2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23e=[]\n",
    "author23e=[]\n",
    "vertical23e=[]\n",
    "headline23e=[]\n",
    "description23e=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author23e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical23e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "2aaff85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23e=pd.DataFrame({})\n",
    "df23e['Date']=date23e[:1]\n",
    "df23e['Author']=author23e[:1]\n",
    "df23e['Vertical']=vertical23e[:1]\n",
    "df23e['Healines']=headline23e[:1]\n",
    "df23e['Description']=description23e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9ce9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "505e7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23f=[]\n",
    "author23f=[]\n",
    "vertical23f=[]\n",
    "headline23f=[]\n",
    "description23f=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author23f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical23f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "b2ccd64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23f=pd.DataFrame({})\n",
    "df23f['Date']=date23f[:1]\n",
    "df23f['Author']=author23f[:1]\n",
    "df23f['Vertical']=vertical23f[:1]\n",
    "df23f['Healines']=headline23f[:1]\n",
    "df23f['Description']=description23f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f353f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "f2007058",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23g=[]\n",
    "author23g=[]\n",
    "vertical23g=[]\n",
    "headline23g=[]\n",
    "description23g=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author23g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|politics']\")\n",
    "for i in ve:\n",
    "    vertical23g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "9f1f815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23g=pd.DataFrame({})\n",
    "df23g['Date']=date23g[:1]\n",
    "df23g['Author']=author23g[:1]\n",
    "df23g['Vertical']=vertical23g[:1]\n",
    "df23g['Healines']=headline23g[:1]\n",
    "df23g['Description']=description23g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac91a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "f8aa1d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23h=[]\n",
    "author23h=[]\n",
    "vertical23h=[]\n",
    "headline23h=[]\n",
    "description23h=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author23h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical23h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "8f180f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23h=pd.DataFrame({})\n",
    "df23h['Date']=date23h[:1]\n",
    "df23h['Author']=author23h[:1]\n",
    "df23h['Vertical']=vertical23h[:1]\n",
    "df23h['Healines']=headline23h[:1]\n",
    "df23h['Description']=description23h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7797e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "b6a25d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "date23i=[]\n",
    "author23i=[]\n",
    "vertical23i=[]\n",
    "headline23i=[]\n",
    "description23i=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date23i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author23i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical23i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline23i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description23i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "103cb63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df23i=pd.DataFrame({})\n",
    "df23i['Date']=date23i[:1]\n",
    "df23i['Author']=author23i[:1]\n",
    "df23i['Vertical']=vertical23i[:1]\n",
    "df23i['Healines']=headline23i[:1]\n",
    "df23i['Description']=description23i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce66b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9dafbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "e6666e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24=[]\n",
    "author24=[]\n",
    "vertical24=[]\n",
    "headline24=[]\n",
    "description24=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author24.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical24.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "55cd53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24=pd.DataFrame({})\n",
    "df24['Date']=date24[:1]\n",
    "df24['Author']=author24[:1]\n",
    "df24['Vertical']=vertical24[:1]\n",
    "df24['Healines']=headline24[:1]\n",
    "df24['Description']=description24[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df2685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "855bb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24a=[]\n",
    "author24a=[]\n",
    "vertical24a=[]\n",
    "headline24a=[]\n",
    "description24a=[]\n",
    "\n",
    "# scrapping details 23 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author24a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical24a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "5803d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24a=pd.DataFrame({})\n",
    "df24a['Date']=date24a[:1]\n",
    "df24a['Author']=author24a[:1]\n",
    "df24a['Vertical']=vertical24a[:1]\n",
    "df24a['Healines']=headline24a[:1]\n",
    "df24a['Description']=description24a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c5ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "dd52bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24b=[]\n",
    "author24b=[]\n",
    "vertical24b=[]\n",
    "headline24b=[]\n",
    "description24b=[]\n",
    "\n",
    "# scrapping details 24 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24b.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author24b.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical24b.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24b.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24b.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "fbd08cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24b=pd.DataFrame({})\n",
    "df24b['Date']=date24b[:1]\n",
    "df24b['Author']=author24b[:1]\n",
    "df24b['Vertical']=vertical24b[:1]\n",
    "df24b['Healines']=headline24b[:1]\n",
    "df24b['Description']=description24b[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a73f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "4a8f9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24c=[]\n",
    "author24c=[]\n",
    "vertical24c=[]\n",
    "headline24c=[]\n",
    "description24c=[]\n",
    "\n",
    "# scrapping details 24 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24c.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author24c.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|nashik']\")\n",
    "for i in ve:\n",
    "    vertical24c.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24c.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24c.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "6aa50ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24c=pd.DataFrame({})\n",
    "df24c['Date']=date24c[:1]\n",
    "df24c['Author']=author24c[:1]\n",
    "df24c['Vertical']=vertical24c[:1]\n",
    "df24c['Healines']=headline24c[:1]\n",
    "df24c['Description']=description24c[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a1b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "02fc3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24d=[]\n",
    "author24d=[]\n",
    "vertical24d=[]\n",
    "headline24d=[]\n",
    "description24d=[]\n",
    "\n",
    "# scrapping details 24 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24d.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author24d.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical24d.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24d.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24d.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "44761f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24d=pd.DataFrame({})\n",
    "df24d['Date']=date24d[:1]\n",
    "df24d['Author']=author24d[:1]\n",
    "df24d['Vertical']=vertical24d[:1]\n",
    "df24d['Healines']=headline24d[:1]\n",
    "df24d['Description']=description24d[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311b3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "14de2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24e=[]\n",
    "author24e=[]\n",
    "vertical24e=[]\n",
    "headline24e=[]\n",
    "description24e=[]\n",
    "\n",
    "# scrapping details 24 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24e.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author24e.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|citizen reporter']\")\n",
    "for i in ve:\n",
    "    vertical24e.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24e.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24e.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "3f447353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24e=pd.DataFrame({})\n",
    "df24e['Date']=date24e[:1]\n",
    "df24e['Author']=author24e[:1]\n",
    "df24e['Vertical']=vertical24e[:1]\n",
    "df24e['Healines']=headline24e[:1]\n",
    "df24e['Description']=description24e[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f4fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "af7ec0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24f=[]\n",
    "author24f=[]\n",
    "vertical24f=[]\n",
    "headline24f=[]\n",
    "description24f=[]\n",
    "\n",
    "# scrapping details 24 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24f.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author24f.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical24f.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24f.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24f.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "63872e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24f=pd.DataFrame({})\n",
    "df24f['Date']=date24f[:1]\n",
    "df24f['Author']=author24f[:1]\n",
    "df24f['Vertical']=vertical24f[:1]\n",
    "df24f['Healines']=headline24f[:1]\n",
    "df24f['Description']=description24f[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bf82e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "971837e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24g=[]\n",
    "author24g=[]\n",
    "vertical24g=[]\n",
    "headline24g=[]\n",
    "description24g=[]\n",
    "\n",
    "# scrapping details 24 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24g.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author24g.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|US']\")\n",
    "for i in ve:\n",
    "    vertical24g.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24g.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24g.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "65489f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24g=pd.DataFrame({})\n",
    "df24g['Date']=date24g[:1]\n",
    "df24g['Author']=author24g[:1]\n",
    "df24g['Vertical']=vertical24g[:1]\n",
    "df24g['Healines']=headline24g[:1]\n",
    "df24g['Description']=description24g[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3be52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "86a4a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24h=[]\n",
    "author24h=[]\n",
    "vertical24h=[]\n",
    "headline24h=[]\n",
    "description24h=[]\n",
    "\n",
    "# scrapping details 24 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24h.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author24h.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical24h.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24h.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24h.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "367e316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24h=pd.DataFrame({})\n",
    "df24h['Date']=date24h[:1]\n",
    "df24h['Author']=author24h[:1]\n",
    "df24h['Vertical']=vertical24h[:1]\n",
    "df24h['Healines']=headline24h[:1]\n",
    "df24h['Description']=description24h[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1100555c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "2a654f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date24i=[]\n",
    "author24i=[]\n",
    "vertical24i=[]\n",
    "headline24i=[]\n",
    "description24i=[]\n",
    "\n",
    "# scrapping details 24 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date24i.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author24i.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|raipur']\")\n",
    "for i in ve:\n",
    "    vertical24i.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline24i.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description24i.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "85a2f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24i=pd.DataFrame({})\n",
    "df24i['Date']=date24i[:1]\n",
    "df24i['Author']=author24i[:1]\n",
    "df24i['Vertical']=vertical24i[:1]\n",
    "df24i['Healines']=headline24i[:1]\n",
    "df24i['Description']=description24i[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57eedbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770901f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "89b7fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "date25=[]\n",
    "author25=[]\n",
    "vertical25=[]\n",
    "headline25=[]\n",
    "description25=[]\n",
    "\n",
    "# scrapping details 25 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date25.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author25.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|UK']\")\n",
    "for i in ve:\n",
    "    vertical25.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline25.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description25.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "0774d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25=pd.DataFrame({})\n",
    "df25['Date']=date25[:1]\n",
    "df25['Author']=author25[:1]\n",
    "df25['Vertical']=vertical25[:1]\n",
    "df25['Healines']=headline25[:1]\n",
    "df25['Description']=description25[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d11b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "0fbeb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date25a=[]\n",
    "author25a=[]\n",
    "vertical25a=[]\n",
    "headline25a=[]\n",
    "description25a=[]\n",
    "\n",
    "# scrapping details 25 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date25a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author25a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical25a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline25a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description25a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "23b2f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df25a=pd.DataFrame({})\n",
    "df25a['Date']=date25a[:1]\n",
    "df25a['Author']=author25a[:1]\n",
    "df25a['Vertical']=vertical25a[:1]\n",
    "df25a['Healines']=headline25a[:1]\n",
    "df25a['Description']=description25a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6a046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d1f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "b57ea991",
   "metadata": {},
   "outputs": [],
   "source": [
    "date26=[]\n",
    "author26=[]\n",
    "vertical26=[]\n",
    "headline26=[]\n",
    "description26=[]\n",
    "\n",
    "# scrapping details 25 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date26.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author26.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical26.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline26.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description26.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "a5051aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df26=pd.DataFrame({})\n",
    "df26['Date']=date26[:1]\n",
    "df26['Author']=author26[:1]\n",
    "df26['Vertical']=vertical26[:1]\n",
    "df26['Healines']=headline26[:1]\n",
    "df26['Description']=description26[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f66635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "c09a33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date26a=[]\n",
    "author26a=[]\n",
    "vertical26a=[]\n",
    "headline26a=[]\n",
    "description26a=[]\n",
    "\n",
    "# scrapping details 26 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date26a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author26a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Pakistan']\")\n",
    "for i in ve:\n",
    "    vertical26a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline26a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description26a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "9adec7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df26a=pd.DataFrame({})\n",
    "df26a['Date']=date26a[:1]\n",
    "df26a['Author']=author26a[:1]\n",
    "df26a['Vertical']=vertical26a[:1]\n",
    "df26a['Healines']=headline26a[:1]\n",
    "df26a['Description']=description26a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e97b46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9b0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "721f5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "date27=[]\n",
    "author27=[]\n",
    "vertical27=[]\n",
    "headline27=[]\n",
    "description27=[]\n",
    "\n",
    "# scrapping details 27 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date27.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author27.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical27.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline27.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description27.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "8542b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df27=pd.DataFrame({})\n",
    "df27['Date']=date27[:1]\n",
    "df27['Author']=author27[:1]\n",
    "df27['Vertical']=vertical27[:1]\n",
    "df27['Healines']=headline27[:1]\n",
    "df27['Description']=description27[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b03cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "f93f693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date27a=[]\n",
    "author27a=[]\n",
    "vertical27a=[]\n",
    "headline27a=[]\n",
    "description27a=[]\n",
    "\n",
    "# scrapping details 27 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date27a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author27a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical27a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline27a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description27a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "7bb35954",
   "metadata": {},
   "outputs": [],
   "source": [
    "df27a=pd.DataFrame({})\n",
    "df27a['Date']=date27a[:1]\n",
    "df27a['Author']=author27a[:1]\n",
    "df27a['Vertical']=vertical27a[:1]\n",
    "df27a['Healines']=headline27a[:1]\n",
    "df27a['Description']=description27a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af42ad3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a30778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "114bc669",
   "metadata": {},
   "outputs": [],
   "source": [
    "date28=[]\n",
    "author28=[]\n",
    "vertical28=[]\n",
    "headline28=[]\n",
    "description28=[]\n",
    "\n",
    "# scrapping details 28 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date28.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author28.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical28.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline28.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description28.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "801437a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df28=pd.DataFrame({})\n",
    "df28['Date']=date28[:1]\n",
    "df28['Author']=author28[:1]\n",
    "df28['Vertical']=vertical28[:1]\n",
    "df28['Healines']=headline28[:1]\n",
    "df28['Description']=description28[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e39be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "06018471",
   "metadata": {},
   "outputs": [],
   "source": [
    "date28a=[]\n",
    "author28a=[]\n",
    "vertical28a=[]\n",
    "headline28a=[]\n",
    "description28a=[]\n",
    "\n",
    "# scrapping details 28 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date28a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author28a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical28a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline28a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description28a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "7b7bdcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df28a=pd.DataFrame({})\n",
    "df28a['Date']=date28a[:1]\n",
    "df28a['Author']=author28a[:1]\n",
    "df28a['Vertical']=vertical28a[:1]\n",
    "df28a['Healines']=headline28a[:1]\n",
    "df28a['Description']=description28a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34348414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5571dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "60c866b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "date29=[]\n",
    "author29=[]\n",
    "vertical29=[]\n",
    "headline29=[]\n",
    "description29=[]\n",
    "\n",
    "# scrapping details 29 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date29.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author29.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|school and colleges']\")\n",
    "for i in ve:\n",
    "    vertical29.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline29.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description29.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "4795b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df29=pd.DataFrame({})\n",
    "df29['Date']=date29[:1]\n",
    "df29['Author']=author29[:1]\n",
    "df29['Vertical']=vertical29[:1]\n",
    "df29['Healines']=headline29[:1]\n",
    "df29['Description']=description29[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b9c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "a13401a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "date29a=[]\n",
    "author29a=[]\n",
    "vertical29a=[]\n",
    "headline29a=[]\n",
    "description29a=[]\n",
    "\n",
    "# scrapping details 29 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date29a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author29a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical29a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline29a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description29a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "1ba46c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df29a=pd.DataFrame({})\n",
    "df29a['Date']=date29a[:1]\n",
    "df29a['Author']=author29a[:1]\n",
    "df29a['Vertical']=vertical29a[:1]\n",
    "df29a['Healines']=headline29a[:1]\n",
    "df29a['Description']=description29a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad714a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2d783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "8d524679",
   "metadata": {},
   "outputs": [],
   "source": [
    "date30=[]\n",
    "author30=[]\n",
    "vertical30=[]\n",
    "headline30=[]\n",
    "description30=[]\n",
    "\n",
    "# scrapping details 30 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date30.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author30.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|india']\")\n",
    "for i in ve:\n",
    "    vertical30.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline30.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description30.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "59255f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df30=pd.DataFrame({})\n",
    "df30['Date']=date30[:1]\n",
    "df30['Author']=author30[:1]\n",
    "df30['Vertical']=vertical30[:1]\n",
    "df30['Healines']=headline30[:1]\n",
    "df30['Description']=description30[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a35665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "ff2f2027",
   "metadata": {},
   "outputs": [],
   "source": [
    "date30a=[]\n",
    "author30a=[]\n",
    "vertical30a=[]\n",
    "headline30a=[]\n",
    "description30a=[]\n",
    "\n",
    "# scrapping details 30 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date30a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author30a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|crime']\")\n",
    "for i in ve:\n",
    "    vertical30a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline30a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description30a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "566ea595",
   "metadata": {},
   "outputs": [],
   "source": [
    "df30a=pd.DataFrame({})\n",
    "df30a['Date']=date30a[:1]\n",
    "df30a['Author']=author30a[:1]\n",
    "df30a['Vertical']=vertical30a[:1]\n",
    "df30a['Healines']=headline30a[:1]\n",
    "df30a['Description']=description30a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a880a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1018d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "c5048358",
   "metadata": {},
   "outputs": [],
   "source": [
    "date31=[]\n",
    "author31=[]\n",
    "vertical31=[]\n",
    "headline31=[]\n",
    "description31=[]\n",
    "\n",
    "# scrapping details 31 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date31.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']\")\n",
    "for i in at:\n",
    "     author31.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L2_parent|civic issues']\")\n",
    "for i in ve:\n",
    "    vertical31.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline31.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description31.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "9e9444b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df31=pd.DataFrame({})\n",
    "df31['Date']=date31[:1]\n",
    "df31['Author']=author31[:1]\n",
    "df31['Vertical']=vertical31[:1]\n",
    "df31['Healines']=headline31[:1]\n",
    "df31['Description']=description31[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ca903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "30ef1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date31a=[]\n",
    "author31a=[]\n",
    "vertical31a=[]\n",
    "headline31a=[]\n",
    "description31a=[]\n",
    "\n",
    "# scrapping details 31 july 2019\n",
    "\n",
    "dt=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/span\")\n",
    "for i in dt:\n",
    "    date31a.append(i.text)\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "at=driver.find_elements_by_xpath(\"//div[@class='yYIu- byline']/a\")\n",
    "for i in at:\n",
    "     author31a.append(i.text)\n",
    "   \n",
    "        \n",
    "    \n",
    "ve=driver.find_elements_by_xpath(\"//a[@data-ga='nav_menu|L1_parent|Cricket']\")\n",
    "for i in ve:\n",
    "    vertical31a.append(i.text)\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "hd=driver.find_elements_by_xpath(\"//h1[@class='_1Y-96']\")\n",
    "for i in hd:\n",
    "     headline31a.append(i.text)\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "desc=driver.find_elements_by_xpath(\"//div[@class='_3YYSt clearfix  ']\")\n",
    "for i in desc:\n",
    "    description31a.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "64d7a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df31a=pd.DataFrame({})\n",
    "df31a['Date']=date31a[:1]\n",
    "df31a['Author']=author31a[:1]\n",
    "df31a['Vertical']=vertical31a[:1]\n",
    "df31a['Healines']=headline31a[:1]\n",
    "df31a['Description']=description31a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00502090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362ca36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "10fa9311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creatig Dataframes\n",
    "dfa=pd.concat([df1,df1a,df1b,df1c,df1d,df1e,df1f,df1g,df1h,df1i])\n",
    "\n",
    "dfb=pd.concat([df2,df2a,df2b,df2c,df2d,df2e,df2f,df2g,df2h,df2i])\n",
    "\n",
    "dfc=pd.concat([df3,df3a,df3b,df3c,df3d,df3e,df3f,df3g,df3h,df3i])\n",
    "\n",
    "dfd=pd.concat([df4,df4a,df4b,df4c,df4d,df4e,df4f,df4g,df4h,df4i])\n",
    "\n",
    "dfe=pd.concat([df5,df5a,df5b,df5c,df5d,df5e,df5f,df5g,df5h,df5i])\n",
    "\n",
    "dff=pd.concat([df6,df6a,df6b,df6c,df6d,df6e,df6f,df6g,df6h,df6i])\n",
    "\n",
    "dfg=pd.concat([df7,df7a,df7b,df7c,df7d,df7e,df7f,df7g,df7h,df7i])\n",
    "\n",
    "dfh=pd.concat([df8,df8a,df8b,df8c,df8d,df8e,df8f,df8g,df8h,df8i])\n",
    "\n",
    "dfi=pd.concat([df9,df9a,df9b,df9c,df9d,df9e,df9f,df9g,df9h,df9i])\n",
    "\n",
    "dfj=pd.concat([df10,df10a,df10b,df10c,df10d,df10e,df10f,df10g,df10h,df10i])\n",
    "\n",
    "dfk=pd.concat([df11,df11a,df11b,df11c,df11d,df11e,df11f,df11g,df11h,df11i])\n",
    "\n",
    "dfl=pd.concat([df12,df12a,df12b,df12c,df12d,df12e,df12f,df12g,df12h,df12i])\n",
    "\n",
    "dfn=pd.concat([df14,df14a,df14b,df14c,df14d,df14e,df14f,df14g,df14h,df14i])\n",
    "\n",
    "dfo=pd.concat([df15,df15a,df15b,df15c,df15d,df15e,df15f,df15g,df15h,df15i])\n",
    "\n",
    "dfp=pd.concat([df16,df16a,df16b,df16c,df16d,df16e,df16f,df16g,df16h,df16i])\n",
    "\n",
    "dfq=pd.concat([df17,df17a,df17b,df17c,df17d,df17e,df17f,df17g,df17h,df17i])\n",
    "\n",
    "dfr=pd.concat([df18,df18a,df18b,df18c,df18d,df18e,df18f,df18g,df18h,df18i])\n",
    "\n",
    "dfs=pd.concat([df19,df19a,df19b,df19c,df19d,df19e,df19f,df19g,df19h,df19i])\n",
    "\n",
    "dft=pd.concat([df20,df20a,df20b,df20c,df20d,df20e,df20f,df20g,df20h,df20i])\n",
    "\n",
    "dfu=pd.concat([df21,df21a,df21b,df21c,df21d,df21e,df21f,df21g,df21h,df21i])\n",
    "\n",
    "dfv=pd.concat([df22,df22a,df22b,df22c,df22d,df22e,df22f,df22g,df22h,df22i])\n",
    "\n",
    "dfw=pd.concat([df23,df23a,df23b,df23c,df23d,df23e,df23f,df23g,df23h,df23i])\n",
    "\n",
    "dfx=pd.concat([df24,df24a,df24b,df24c,df24d,df24e,df24f,df24g,df24h,df24i])\n",
    "\n",
    "dfy=pd.concat([df25,df25a])\n",
    "\n",
    "dfz=pd.concat([df26,df26a])\n",
    "\n",
    "dfz1=pd.concat([df27,df27a])\n",
    "\n",
    "dfz2=pd.concat([df28,df28a])\n",
    "\n",
    "dfz3=pd.concat([df29,df29a])\n",
    "\n",
    "dfz4=pd.concat([df30,df31a])\n",
    "\n",
    "dfz5=pd.concat([df31,df31a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "9d1395af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([dfa,dfb,dfc,dfe,dfd,dff,dfg,dfh,dfi,dfj,dfk,dfl,dfm,dfn,dfo,dfp,dfq,dfr,dfs,dft,dfu,dfv,dfw,dfx,dfy,dfz,dfz1,dfz2,dfz3,dfz4,dfz5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "94ea4c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reset=df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "926d5306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Vertical</th>\n",
       "      <th>Healines</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jul 1, 2019, 08:22 IST</th>\n",
       "      <td>TNN / Jul 1, 2019, 08:22 IST</td>\n",
       "      <td>CIVIC ISSUES</td>\n",
       "      <td>BMC invites feedback on Aarey Colony trees to ...</td>\n",
       "      <td>MUMBAI: A day after the Bombay high court lift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Updated: Jul 1, 2019, 08:23 IST</th>\n",
       "      <td>TNN / Updated: Jul 1, 2019, 08:23 IST</td>\n",
       "      <td>CRIME</td>\n",
       "      <td>Chhattisgarh youth visiting brother in Chennai...</td>\n",
       "      <td>CHENNAI: An 18-year-old from Chhattisgarh visi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Updated: Jul 1, 2019, 12:06 IST</th>\n",
       "      <td>Shashank Shekhar</td>\n",
       "      <td>Cricket</td>\n",
       "      <td>ICC World Cup 2019: India give up fight to han...</td>\n",
       "      <td>BIRMINGHAM: India finally met their match in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Updated: Jul 1, 2019, 16:34 IST</th>\n",
       "      <td>Ishita Mishra</td>\n",
       "      <td>City</td>\n",
       "      <td>Auli wedding: Now Joshimath civic body slaps R...</td>\n",
       "      <td>Dehradun: The organisers of the Rs 200-crore w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jul 1, 2019, 08:13 IST</th>\n",
       "      <td>TNN / Jul 1, 2019, 08:13 IST</td>\n",
       "      <td>Madurai</td>\n",
       "      <td>Stick to UGC norms in appointment: HC</td>\n",
       "      <td>MADURAI: The Madurai bench of the Madras high ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jul 29, 2019, 06:38 IST</th>\n",
       "      <td>TNN / Jul 29, 2019, 06:38 IST</td>\n",
       "      <td>CIVIC ISSUES</td>\n",
       "      <td>Three injured in accidents on slippery roads i...</td>\n",
       "      <td>KOLKATA: Wet roads led to three major accident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jul 30, 2019, 06:16 IST</th>\n",
       "      <td>TNN / Jul 30, 2019, 06:16 IST</td>\n",
       "      <td>India</td>\n",
       "      <td>J&amp;K: Officer behind panic letter shunted out</td>\n",
       "      <td>NEW DELHI: Railways on Monday transferred the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Updated: Jul 31, 2019, 08:37 IST</th>\n",
       "      <td>Gaurav Gupta</td>\n",
       "      <td>Cricket</td>\n",
       "      <td>Substance found in cough syrup gets Prithvi Sh...</td>\n",
       "      <td>MUMBAI: Indian cricket was hit by its biggest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jul 31, 2019, 08:12 IST</th>\n",
       "      <td>TNN / Jul 31, 2019, 08:12 IST</td>\n",
       "      <td>CIVIC ISSUES</td>\n",
       "      <td>Chennai: Corporates roped in for lake restorat...</td>\n",
       "      <td>CHENNAI: Greater Chennai Corporation officials...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Updated: Jul 31, 2019, 08:37 IST</th>\n",
       "      <td>Gaurav Gupta</td>\n",
       "      <td>Cricket</td>\n",
       "      <td>Substance found in cough syrup gets Prithvi Sh...</td>\n",
       "      <td>MUMBAI: Indian cricket was hit by its biggest ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 Author  \\\n",
       "Date                                                                      \n",
       "Jul 1, 2019, 08:22 IST                     TNN / Jul 1, 2019, 08:22 IST   \n",
       "Updated: Jul 1, 2019, 08:23 IST   TNN / Updated: Jul 1, 2019, 08:23 IST   \n",
       "Updated: Jul 1, 2019, 12:06 IST                        Shashank Shekhar   \n",
       "Updated: Jul 1, 2019, 16:34 IST                           Ishita Mishra   \n",
       "Jul 1, 2019, 08:13 IST                     TNN / Jul 1, 2019, 08:13 IST   \n",
       "...                                                                 ...   \n",
       "Jul 29, 2019, 06:38 IST                   TNN / Jul 29, 2019, 06:38 IST   \n",
       "Jul 30, 2019, 06:16 IST                   TNN / Jul 30, 2019, 06:16 IST   \n",
       "Updated: Jul 31, 2019, 08:37 IST                           Gaurav Gupta   \n",
       "Jul 31, 2019, 08:12 IST                   TNN / Jul 31, 2019, 08:12 IST   \n",
       "Updated: Jul 31, 2019, 08:37 IST                           Gaurav Gupta   \n",
       "\n",
       "                                      Vertical  \\\n",
       "Date                                             \n",
       "Jul 1, 2019, 08:22 IST            CIVIC ISSUES   \n",
       "Updated: Jul 1, 2019, 08:23 IST          CRIME   \n",
       "Updated: Jul 1, 2019, 12:06 IST        Cricket   \n",
       "Updated: Jul 1, 2019, 16:34 IST           City   \n",
       "Jul 1, 2019, 08:13 IST                 Madurai   \n",
       "...                                        ...   \n",
       "Jul 29, 2019, 06:38 IST           CIVIC ISSUES   \n",
       "Jul 30, 2019, 06:16 IST                  India   \n",
       "Updated: Jul 31, 2019, 08:37 IST       Cricket   \n",
       "Jul 31, 2019, 08:12 IST           CIVIC ISSUES   \n",
       "Updated: Jul 31, 2019, 08:37 IST       Cricket   \n",
       "\n",
       "                                                                           Healines  \\\n",
       "Date                                                                                  \n",
       "Jul 1, 2019, 08:22 IST            BMC invites feedback on Aarey Colony trees to ...   \n",
       "Updated: Jul 1, 2019, 08:23 IST   Chhattisgarh youth visiting brother in Chennai...   \n",
       "Updated: Jul 1, 2019, 12:06 IST   ICC World Cup 2019: India give up fight to han...   \n",
       "Updated: Jul 1, 2019, 16:34 IST   Auli wedding: Now Joshimath civic body slaps R...   \n",
       "Jul 1, 2019, 08:13 IST                        Stick to UGC norms in appointment: HC   \n",
       "...                                                                             ...   \n",
       "Jul 29, 2019, 06:38 IST           Three injured in accidents on slippery roads i...   \n",
       "Jul 30, 2019, 06:16 IST              J&K: Officer behind panic letter shunted out   \n",
       "Updated: Jul 31, 2019, 08:37 IST  Substance found in cough syrup gets Prithvi Sh...   \n",
       "Jul 31, 2019, 08:12 IST           Chennai: Corporates roped in for lake restorat...   \n",
       "Updated: Jul 31, 2019, 08:37 IST  Substance found in cough syrup gets Prithvi Sh...   \n",
       "\n",
       "                                                                        Description  \n",
       "Date                                                                                 \n",
       "Jul 1, 2019, 08:22 IST            MUMBAI: A day after the Bombay high court lift...  \n",
       "Updated: Jul 1, 2019, 08:23 IST   CHENNAI: An 18-year-old from Chhattisgarh visi...  \n",
       "Updated: Jul 1, 2019, 12:06 IST   BIRMINGHAM: India finally met their match in t...  \n",
       "Updated: Jul 1, 2019, 16:34 IST   Dehradun: The organisers of the Rs 200-crore w...  \n",
       "Jul 1, 2019, 08:13 IST            MADURAI: The Madurai bench of the Madras high ...  \n",
       "...                                                                             ...  \n",
       "Jul 29, 2019, 06:38 IST           KOLKATA: Wet roads led to three major accident...  \n",
       "Jul 30, 2019, 06:16 IST           NEW DELHI: Railways on Monday transferred the ...  \n",
       "Updated: Jul 31, 2019, 08:37 IST  MUMBAI: Indian cricket was hit by its biggest ...  \n",
       "Jul 31, 2019, 08:12 IST           CHENNAI: Greater Chennai Corporation officials...  \n",
       "Updated: Jul 31, 2019, 08:37 IST  MUMBAI: Indian cricket was hit by its biggest ...  \n",
       "\n",
       "[254 rows x 4 columns]"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "bb018ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving into csv\n",
    "df_reset.to_csv('times_india_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339bf8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61048635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
